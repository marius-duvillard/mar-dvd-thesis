% !TEX root = memoire/main.tex

\chapter{Méthode sans maillage et assimilation de données}

\section{Introduction}

Nous avons vu dans le chapitre précédent que l'assimilation dépendait en particulier de la définition d'un modèle et de son état. Dans le cas de la simulation de l'écoulement au sein du broyeur à boulets, il s'agit principalement de méthodes reposant sur des discrétisations sans maillage comme évoqué en Section~\ref{sec:methode_resolution}. C'est ce type de modélisation qu'il faut prendre en compte dans nos algorithmes d'assimilation de données. Or, si les méthodes d'assimilation peuvent facilement s'exprimer pour des méthodes Eulérienne sur grille ou maillage fixe, elles soulèvent des questionnements lorsque les méthodes reposent sur des discrétisations Lagrangiennes. De plus, il faut aussi différentier la nature de la représentation.Le fait que l'espace soit continu ou discret va également modifier la signification de l'état et sa capacité à être mis à jour.

Dans ce Chapitre, nous reprendrons les principales familles de formulation sans maillage particulaire en particulier en considérant en Section~\ref{sec:part_discret} les méthodes discrétisant un milieu discret et en Section~\ref{sec:part_cont} un milieu continu. Nous évoquerons les sigularités et limites à l'adaptation des méthodes d'assimilation de données comme présentées dans le Chapitre~\ref{sec:da}, et présenterons un état de l'art actuel pour les appliquer. De plus, nous évoquerons la méthode vortex comme une méthode particulaire modèle pour la suite du manuscrit.

\section{Méthodes sans maillage discrétisant un milieu discret}~\label{sec:part_discret}

Les méthodes sans maillage discrètes considèrent les particules comme des objets solides indépendants. Ces entités physiques sont caractérisées par leur géométries, par des propriétés intrasèques conservés comme la masse ou l'inertie, et des variables cinématiques comme la vitesse ou l'accélération. Les particules interagissent entre elles au travers de lois de contact, de frottement et de cohésion. L'objectif est de déterminer la trajectoire des particules. Parmis ces méthodes, on peut mentionner la méthode des éléments discrets (DEM)~\cite{radjai:hal-00691805} et la méthode de dynamique des contacts (CD)~\cite{moreau:hal-01824750}. La principale différence entre ces deux méthodes est de considérer respectivement des particules déformables ou non. Sans perte de généralité pour l'applicabilité au problème d'assimilation, nous présenterons la méthode classique DEM.

\subsection{Méthodes des éléments discrets, \textit{Discrete element method}(DEM)}

La DEM~\cite{cundall_discrete_1979} est une extension du problème à $N$-corps introduit dans les années 60 aussi bien pour la dynamique moléculaire~\cite{Alder1959}, la dynamique des fluides~\cite{Allen1987}, ou encore l'astrophysique~\cite{vonHoerner1960}.
La méthode consiste à considérer le mouvement d'un ensemble de $N$ grains composant le milieu.

Le principe fondamental de la dynamique s'applique sur cet ensemble, et s'exprime pour chaque particule sous la forme

\begin{equation*}
    \left\{
    \begin{aligned}
         & m_{i} \frac{ d^{2}\bm{r}_i }{dt^2}=\bm{f}_{i},\; i=1\ldots N      \\
         & I_{i} \frac{d \bm{\omega}_{i}}{dt}=\bm{\Gamma}_{i},\; i=1\ldots N
    \end{aligned}
    \right.
\end{equation*}où $N$ est le nombre de grains, $m_{i}$ est la masse, $I_i$ est le moment d'inertie, $\bm{r}_{i}$ est la position, $\bm{\omega_{i}}$ est la rotation, $\bm{f}_{i}$ est la force exercée sur le grain considéré et $\bm{\Gamma_{i}}$ le moment associé à la force $\bm{f}_{i}$.

Le couplace entre particules s'exprime au travers de la force $\bm{f}_{i}$ qui se décomposée comme
\begin{equation*}
    \bm{f}_{i}=\underset{{\scriptstyle j\neq i}}{\sum}\bm{f}^{c}_{ij}+\bm{f}_{ext}
\end{equation*}

où $\underset{{\scriptstyle j\neq i}}{\sum}\bm{f}^{c}_{ij}$ représente les forces induites par le contact avec les particules $j$ et $\bm{f}_{ext}$ sont celles appliquées au centre de la particule $i$ (par exemple la force de gravité).

Les forces de contact sont décrite par des loi de contact entre grains, et entre grains et la paroi. Dans le cas élastique, la modèle de Hertz est adapté pour décrire l'intéraction normale. Le modèle Hertz-Mindlin permet de déterminer les interactions tangentielles élastiques. Ces loi sont fonctions de l'interpénétration et de la vitesse relative interpaticules. Par exemple, dans le cas de particules sphérique l'interpénétration est défini comme $\delta_{ij} = \norm{\bm x_i - \bm x_j} - (R_i - R_j)$ où $\bm x$  est la position du centre du grain et $R$ le rayon d'une particule.
La force de contact tend ainsi à pénaliser l'interpénétration via des coefficients de raideur $k$ et d'amortissement $\gamma$ qui dépendent des propriétés mécaniques des grains de de la paroi.

Il existe plusieurs algorithme pour résoudre numériquement les équations de la dynamique. Le plus utilisé est l'algorithme de Verlet en vitesse~\cite{verlet_1982}.
% Le processus de simulation DEM dans un mélangeur-broyeur commence par la définition des propriétés des particules et des conditions initiales du système. Le mouvement de chaque particule est ensuite calculé en résolvant les équations de Newton pour le mouvement et la rotation. Ces calculs tiennent compte des forces et des moments résultant des collisions et des interactions entre particules, ainsi que de l'interaction des particules avec les parois du broyeur.

\section{Méthodes sans maillage discrétisant un milieu continue}\label{sec:part_cont}
Nous envisageons des méthodes par particules pour résoudre des problèmes continus en mécanique des fluides ou des solides. Cela inclut des méthodes telles que l'hydrodynamique par particules lissées (SPH) \cite{lucy_1977,gingold_monaghan_sph_1977} et la méthode des vortex (VM) \cite{cottet_vortex_2000}, et s'étend à d'autres méthodes comme la méthode des points de matériau (MPM) \cite{sulsky_particle_1994}. Elles partagent toutes de décomposer cette fois le domaine en un ensemble $\mathcal{P}$ de particules qui suivent la dynamique du problème. Ainsi, la discrétisation suit la transformation appliquée au milieu en transportant des quantités attachées à chaque particule. Elles sont en cela des méthodes Lagrangienne.

\subsection{Formulation particulaire}

\subsubsection{Discrétisation par particules}

La solution représentée par le jeu de particule est obtenue grâce à deux éléments: une appproximation grâce à un noyau de lissage et l'approximation particulaire d'un opérateur intégral. Si la représentation de la solution peut évoluer suivant la méthode (en particulier avec la méthode MPM), la solution peut toujours être exprimé de cette manière suivant le choix du noyau.

Tout champ relativement régulier $\bm{u}$ sur $\Omega$ peut être écrit grâce à la propriété de filtrage de Dirac

\begin{equation*}
    \bm{u}(\bm{z}) = \int_{\Omega} \bm{u}(\bm{z'}) \delta(\bm{z'} - \bm{z})  d\bm{z'},
\end{equation*}avec $\delta$ la distribution de Dirac.

Une fonction de noyau $\phi_\varepsilon$ est introduite pour obtenir une estimation moyenne $\langle \bm{u} \rangle$ de $\bm{u}$ telle que

\begin{equation*}
    \langle \bm{u}(\bm{z}) \rangle = \int_{\Omega} \bm{u}(\bm{z'}) \phi_\varepsilon(\bm{z}-\bm{z'}) d\bm{z},
\end{equation*}où $\varepsilon$ est la longueur de lissage. Le noyau lisse doit au moins respecter les propriétés suivantes

\begin{eqnarray*}
    && \int_{\Omega} \phi_\varepsilon(\bm{z}) d\bm{z} = 1,      \\
    && \phi_\varepsilon(\bm{z}) \to \delta(z), \quad \varepsilon \to 0, \\
    && \phi_\varepsilon(\bm{z}) \in C^k,  \quad k \geq 1,
\end{eqnarray*} où les deux premières propriétés sont des propriétés résiduelles de la distribution de Dirac et la dernière est une exigence de différentiabilité nécessaire pour approcher les opérateurs différentielles.

La fonction moyenne $\langle \bm{u} \rangle$ est ensuite utilisée pour approximer la fonction d'origine.

Dans un second temps, le domaine d'origine $\Omega$ est subdivisé avec $N_p$ sous-domaines $\Omega_p$ associés à une particule Lagrangienne à l'emplacement $z_p \in \Omega_p$. Nous notons $V_p$ le volume de $\Omega_p$. Cette discrétisation est ensuite utilisée pour approximer la fonction moyenne de telle sorte que

\begin{eqnarray*}~\label{eq:part_approx}
    \langle \bm{u}(\bm{z}) \rangle &=& \sum_p \int_{\Omega_p} \bm{u}(\bm{z'}) \phi_\varepsilon(\bm{z}-\bm{z'}) d\bm{z'} \\
    &\approx& \sum_p \bm{u}(\bm{z}_p) V_p \phi_\varepsilon (\bm{z}-\bm{z}_p) \\
    &\approx& \sum_p \bm{U}_p \phi_\varepsilon (\bm{z}-\bm{z}_p).
\end{eqnarray*}

Ainsi, toute fonction définie sur une discrétisation par particules est définie par un ensemble de positions de particules $\bm{z}_p$ associées à une valeur de particule $\bm{U}_p = \bm{u}(z_p) V_p$ et un noyau lisse $\phi_\varepsilon$.

Sur la base de cette discrétisation, l'opérateur différentiel peut être dérivé à travers cette formulation.

Tout comme le champ $\bm u$, la même interpolation peut être appliquée pour obtenir

\begin{equation*}
    \nabla \bm{u}(\bm{z}) = \sum_p \bm{U}_p \nabla \phi_\varepsilon (\bm{z}-\bm{z}_p).
\end{equation*}

Ils existent toutefois une grande variété de formule pour approximer l'opérateur gradient. Dans ces cas, ce sont les propriétés de conservation associées au champ qui sont privilégiées.
Généralement, un terme additionnel est introduit lorsque le champ est évalué à la position d'une particule $q$ tel que

\begin{equation*}
    \nabla \bm{u}(\bm{z}_p) = \sum_q (\bm{U}_q - \bm{U}_p) \nabla \phi_\varepsilon (\bm{z_q}-\bm{z}_p)
\end{equation*}, où $\sum_q \bm{U}_p \nabla \phi_\varepsilon (\bm{z_q}-\bm{z}_p)$ est nul par propriété de localisation du noyau $\phi_\varepsilon$.

% Finalement dire qu'il y a donc des équations qui permettent de définir l'évolution des intensités ainsi que des positions.

\subsection{Exemple de fonctions de noyau}

Plusieurs noyaux ont été utilisés en fonction de la méthode. La formulation originale de la MPM n'utilisait pas de noyau de substitution et écrivait la densité comme suit

\begin{equation*}
    \bm{u}(\bm{z}) = \sum_p \bm{U}_p \phi_\varepsilon (\bm{z}-\bm{z}_p)
\end{equation*}

Et la résolution est basée sur une projection sur une grille de fond associée à certaines fonctions de forme \cite{sulsky_particle_1994}.

La méthode GIMP est une formulation différente qui utilise la fonction de Heaviside \cite{bardenhagen_generalized_2004} et associe donc un volume autour de chaque particule

\begin{equation*}
    M_1(r) = \frac{\alpha}{\varepsilon}\left\{\begin{aligned}
         & 1; & r \leq \varepsilon \\
         & 0; & \text{sinon}
    \end{aligned}
    \right.
\end{equation*}où $r = \norm{\bm{z}}_2$.

Cette méthode a été introduite pour éviter le problème de passage de cellule lorsque une particule se déplace d'une cellule à une autre à travers la grille de fond.

Dans la méthode SPH, comme son nom l'indique, un noyau lisse est associé pour approximer la solution. Théoriquement, il pourrait s'agir de la fonction de noyau gaussien

\begin{equation*}
    \phi_g(r) = \frac{1}{{(\pi \varepsilon^2)}^{d/2}} \exp(-r^2/\varepsilon^2)
\end{equation*}.

Ce noyau est infiniment différentiable mais défini sur un support non compact. En pratique, nous utilisons une coupure pour supprimer les valeurs négligeables pour une grande distance par rapport à une particule.

D'autres noyaux, basés sur des fonctions B-Spline pour travailler sur un support compact. Ces fonctions sont également positives, ce qui est une exigence pour certains champs comme la densité.

Par exemple, le B-spline quadratique, que nous appelons $M_3$, est défini avec
\begin{equation}~\label{quadratic_kernel}
    M_3(r) = \frac{\alpha}{\varepsilon^d}\left\{ \begin{aligned}
         & \frac{3}{4} - |q|^2                            & 0 \leq           & |q| < \frac{1}{2} \\
         & \frac{1}{2} {\left(\frac{3}{2} - |q|\right)}^2 & \frac{1}{2} \leq & |q| < \frac{3}{2} \\
         & 0                                              & \frac{3}{2} \leq & |q|
    \end{aligned}
    \right.
\end{equation}avec $r = \norm{z}_2 $ et $q = r / \varepsilon$ et $\alpha$ la condition de normalisation et $d$ la dimension spatiale.

Ce noyau garantit la continuité $C^1$.
Le noyau cubique est un autre noyau B-Spline qui est
\begin{eqnarray}~\label{cubic_kernel}
    M_4(r) &=&  \frac{\alpha}{\varepsilon^d} \left\{ \begin{aligned}
         & \frac{1}{6}{(-|q|+2)}^3 - \frac{4}{6}{(-|q|+1)}^3 & 0 \leq      & |q| \leq  1 & \\
         & \frac{1}{6}{(- |q|+2)}^3                          & 1      \leq & |q| \leq 2  & \\
         & 0                                                 & 2 \leq      & |q|
    \end{aligned}
    \right.
\end{eqnarray}

Dans ce dernier cas, le facteur de normalisation $\alpha$ est

\begin{equation*}
    \alpha = \left\{ \begin{aligned}
         & 1;    \quad      & 1\text{ d} \\
         & 30/14 \pi; \quad & 2\text{ d} \\
         & 3/ 2\pi; \quad   & 3\text{ d}
    \end{aligned}
    \right.
\end{equation*}

Notez que ces noyaux ont été définis avec la coordonnée radiale $r$. Une autre possibilité serait de définir le noyau multidimensionnel comme le produit tensoriel du noyau 1D

\subsubsection{Distribution particulaire admissible}~\label{sec:part_admissible}

Les méthodes sans maillage sont ici des méthodes d'appoximation de champs continus. Ces discrétisations doivent ainsi vérifier un certain nombre de critère pour être conforme à la solution. Il s'agit en particulier de donner ici des critères de régularité pour définir si une méthode d'interpolation sans maillage est valide. On trouvera des détailes supplémentaires dans le livre~\cite{s_li_meshfree_2004} en section 4.

On rappelle tout d'abord ce qu'est le support d'une particule $p$. Chaque particule est associée à une fonction d'interpolation $\phi_\varepsilon(\bm{z})$. Le support compact est donc

\begin{equation*}
    S_p = \{\bx \mid \| \phi_\varepsilon \bx - \bx_p \| > 0\} \cap \Omega,
\end{equation*}

On définit également $\rho_p$ le rayon du support compact comme
\begin{equation*}
    \rho_p =  \max \{\| \bx - \bx_p \| > 0 \mid \bx \in S_p\}.
\end{equation*}

C'est l'ensemble de ces sous domaines qui forment la distribution particulaire. Nous supposons un nombre fini de particules. % et un rayon de support homogène $\rho = \rho_I$.

\begin{definition}
    On définit une distribution admissible selon plusieurs conditions
    \begin{enumerate}
        \item L'union des supports de particules
              \begin{equation*}
                  S:= \bigcup_{p \in \mathcal P} S_p
              \end{equation*}
              est inclus dans le domaine $\bar \Omega$ dans lequel réside réside de tel sorte que $\bar \Omega	\subseteq S$.
        \item $\forall \bx \in \bar \Omega$, il existe un boule %\label{item:cond2}
              \begin{equation}
                  \mathcal B(x) = \{x \mid \|\bx - \bar \bx\| < \rho\}
              \end{equation}tel que le nombre de particule dans $\mathcal B$ satisfait deux bornes $0 < N_{min} < N_{max} < \inf$
              \begin{equation*}
                  N_{min} \leq N \leq N_{max}
              \end{equation*} de telle sorte que la matrice des moments vérifie les conditions suivante
              \begin{itemize}
                  \item la matrice de moment est de dimension finie ;
                  \item la martice de moment est inversible ;
                  \item la matrice de moment est bien conditionnée.
              \end{itemize}
        \item Pour $\Omega \in \mathbb R^d$, il est nécessaire que $B(x)$ admette au moins $d+1$ particules dont les vecteurs positions sont distincts, de cette manière la matrice de moment est nécessairement inversible.
    \end{enumerate}
\end{definition}

La condition 1 est une condition de recouvrement. Cette dernière est une condition nécessaire de la condition 2. Cette dernière peut être appelée vu comme une condition de chevauchement, nécessaire afin de "lier" les particules entre elles. La définition d'admissibilité a été développée en terme de ($\rho, p$)-régularité par Han et Meng~\cite{HAN20016157} ou bien par Duarte et Oden~\cite{duarte1996hp}.

Cette définition est déterminante pour pouvoir appliquer les schémas d'interpolation définis dans la Section~\ref{sec:approx_part}.

\subsection{Hydrodynamique des particules lissées, \textit{Smoothed particle hydrodynamics} (SPH)}

La méthode SPH a étét développée indépendemment par Lucy~\cite{lucy_1977}, et Gingold et Monhagan~\cite{gingold_monaghan_sph_1977}. Elle a été formulé initialement pour dess problème de formation et d'évolution des systèmes stellaires. Tout comme en mécanique quantique sont but est de réprésenter le système discret en le lissant pour obtenir un milieu continu discrétisé par un ensemble de particules. En mécanique, cette méthode est vu comme une méthode de discrétisation sans maillage d'un milieu continu.
Elle consiste à résoudre la forme forte des équations de la dynamique en approchant les champs et les opérateurs différentiels à l'aide de l'approximation particulaire et l'approximation par noyau précédemment évoqué.

Les équations résoluent sont l'équation de continuité et l'équation de conservation de la quantité de mouvement à travers l'équation d'Euler

\begin{eqnarray*}
    \frac{d\rho}{dt} + \rho \nabla \cdot \bm{v} = 0, \\
    \frac{d\bm v}{dt} = \frac1\rho \nabla \cdot \bm \sigma,
\end{eqnarray*}où $\rho$ est la densité, $\bm v$ la vitesse, $\bm \sigma$ la contraite de Cauchy.

En utilisant la règle d'approximation du gradient le terme $\rho \nabla \cdot \bm{v}$ peut être approximé pour chaque particule, ce qui donne pour l'équation de continuité

\begin{equation*}
    \frac{d\rho_p}{\sum_{q} m_j (\bm v_j - \bm v_i) \cdot \nabla \phi_\varepsilon(\bm z_p - \bm z_q)}.
\end{equation*}

De la même manière, l'équation d'équilibre des quantités de mouvement peut êter discrétisé. La forme suivante est généralement utilisée

\begin{equation*}
    m_p \frac{d \bm v}{dt} = \sum_{q} m_p m_q \left(\frac{\bm \sigma_p}{\rho_p^2} + \frac{\bm \sigma_q}{\rho_q^2} \right) \cdot \nabla \phi_\varepsilon(\bm z_p - \bm z_q).
\end{equation*}

Cette version est symétrique par rapport aux indices $p$ et $q$ ce qui favorise les propriétés de conservation.

Finalement, les équations de la dynamique sont intégrées dans le temps généralement à l'aide d'un algorithme dit \textit{leap-frog}.

\subsection{Méthode des points matériaux, \textit{Material Point Method} (MPM)}

La méthode des points matériaux (MPM) est une autre méthode particulaire qui utilise une double description: lagrangienne et eulérienne. Tout comme la méthode SPH, elle utilise une discrétisation particulaire, les points matériaux, qui en se déplaçant transportent certaines variables internes. D'autre part, l'interpolation du champ de déplacement est réalisé à l'aide de coordonnées spatiales détachées des éléments matériels, généralement sur une grille régulière. Les deux discrétisations interagissent au travers l'opérateur de projection interpolation entre particules et les noeuds et de la grille qui les entourent. Cette méthode fait parti de la famille \textit{particle-in-cell} (PIC). La méthode MPM est un adaptation en mécanique des solides développé par Sulsky et al.~\cite{sulsky_particle_1994} à partir de la méthode FLIP de Brackbill~\cite{brackbill_flip_1988} en mécanique des fluides.

Comme en élément finis, la méthode MPM consiste à résoudre le problème aux valeurs sous sa forme faible
% Le problème aux conditions limites, sous sa forme forte, se composent des équations d'équilibre, des lois matériaux, de l'équation cinématique et des conditions limites et initiales donnant

% \begin{equation*}
%     \begin{cases}
%         \begin{aligned}
%              & \frac{D \rho}{Dt} + \rho \nabla \cdot \bm v  =  0                          ,                                                                         & \quad \text{(conservation de la masse)}                  \\
%              & \rho \frac{D \bm v}{Dt}                      =  \nabla \cdot \bm \sigma + \rho \bm b,                                                                & \quad  \text{(conservation de la quantité de mouvement)} \\
%              & \bm \sigma = LdC(\bm F),                                                                                                                             & \quad  \text{(loi de comportement)}                      \\
%              & \bm u(\bm z, t) = \bar{\bm u}, \quad \forall \bm z \in \Gamma_u,    \quad  \bm \sigma (\bm z) \cdot \bm n = \bm t, \quad \forall \bm z \in \Gamma_t, & \quad  \text{(conditions limites)}                       \\&\bm v(\bm z, t = 0), \quad \bm \sigma(\bm z, t= 0) = \bm \sigma_0. & \quad  \text{(conditions initiales)} \\
%         \end{aligned}
%     \end{cases}
% \end{equation*}

En introduisant une fonction test $\bm q$, la forme faible de l'équation de conservation du moment s'écrit

\begin{equation*}~\label{eq:form_faible}
    \int_\Omega \rho \bm a \cdot \bm q d\Omega + \int_\Omega \rho \bm \sigma : \nabla \cdot \bm q d\Omega = \int_\Omega \rho \bm b\cdot \bm q d\Omega + \int_{\partial \Omega_t} \bm q \cdot \bm t dS.
\end{equation*}

Le schéma MPM peut être obtenu en concentrant la masse sur $N_p$ particules. La densité est alors représentée comme un somme de dirac

\begin{equation*}
    \rho(\bm z) = \sum_p V_p~\rho_p \delta(\bm z - \bm z_p) = \sum_p m_p \delta(\bm z - \bm z_p)
\end{equation*}

De même, on discrétise la contrainte $\bm \sigma$

\begin{equation*}
    \bm \sigma(x) = \sum_p \bm \sigma_p \delta(\bm z - \bm z_p).
\end{equation*}
On trouve un certain nombre de généralisation dans la littérature comme la méthode GIMP \cite{bardenhagen_generalized_2004} en définissant une représentation particulaire de la densité où les diracs sont remplacés par des fonction caractéristique $\chi_p$ tel que

\begin{equation*}
    \rho(\bm z) = \sum_p m_p \chi(\bm z - \bm z_p)
\end{equation*}.

Finalement, en injectant cette discrétisation de la densité dans l'équation~\eqref{eq:form_faible}

\begin{equation*}
    \sum_p m_p \bm q(\bm z_p(t), t)\cdot \bm a(\bm z_p(t), t) + \sum_p m_p \bm \sigma(\bm z(t), t) : \nabla \bm u(\bm z(t), t) + \int_{\partial \Omega_t} \bm t \bm q dS + \sum_{p} m_p \bm q(X(t), t) \cdot \bm b(X(t), t).
\end{equation*}

Les variables cinématiques sont ensuite discrétisées sur la discrétisation eulérienne. La précédente équation est résolue sur la grille et l'accélération est déterminée sur chaque noeud $I$ de la grille comme

\begin{equation*}
    \sum_{J}^{N_\text{grid}} m_{IJ} \bm a_J = \bm f_I^{\text{int}} + \bm f_I^{\text{ext}}
\end{equation*}

Les deux niveaux de discrétisation communique selon des étapes de projection (\textit{particles to grid}) puis d'interpolation (\textit{grid to particles}). Dans un premier temps, les quantités définies sur les particules sont transférés sur les noeuds de la grille \textit{p2g}.La masse $m_p$, la quantité de mouvement $m_p \bm v_p$ et les forces $\bm f_p$ sont transférées à la grille à l'aide des fonctions de forme $\phi_I$ associé à chaque noeuds. Le transfert classique est détaillé dans l'article fondateur~\cite{sulsky_particle_1994}, cependant des transferts plus complexes ont été développé afin d'offre des schémas stables et conservatifs~\cite{jiang_affine_2015,fu_polynomial_2017,hu_moving_2018}.
Le principe fondementale de la dynamique est alors résolu permettant de déterminer une grille déformée. Finalement, les particules vont suivre la déformation de la grille. Cela aura deux conséquence : La mise à jour de la matrice de déformation, de leurs positions $\bm x_p$ et leurs vitesses $\bm v_p$. Finalement, la grille de calcule peut être effacée et réinitialisée.
Ainsi, ce sont les particules qui concervent toute l'information (grille réinitialisée)
Cette méthode représente un compromis entre les approches par éléments finis et par particules, offrant ainsi une modélisation efficace des interactions matérielles dans des environnements dynamiques et déformables.

\subsection{Méthode vortex}~\label{sec:vortex}

La méthode vortex est une méthode particulaire utilisé pour résoudre  dans le cas d'écoulements incompressibles~\cite{Cottet_Koumoutsakos_2000}. Elle a été pour la première fois développé indépendemment par Prager~\cite{prager1928druckverteilung} et Rosenhead~\cite{rosenhead1931formation}. Elle se base sur la discrétisation du champ de vorticité par un ensemble de particules, et résoud la formulation vorticité-vitesse des équations de Navier-Stokes

\begin{eqnarray*}
    \frac{\partial \bm \omega}{\partial t} + (\bm{u} \cdot \nabla) \bm \omega & = &(\bm \omega \cdot \nabla) \bm u + \nu \Delta \bm \omega, \\
    \Delta u  & =&  -\nabla \times \bm \omega,
\end{eqnarray*}où $\bm{u}$ la vitesse, $\omega= \nabla \times \bm u$ le champ de tourbillon, et $\nu$ pour la viscosité.

Les formes lagrangiennes des équations précédentes deviennent

\begin{eqnarray*}
    \frac{d \bx_p}{dt} = \bm u(\bx_p, t) \\
    \frac{d\bm \omega}{dt} = - [\nabla \times \bm u (\bx_p, t)]\bm \omega_p + \nu \Delta \bm \omega(\bx_p, t)
\end{eqnarray*}

Dans le cas d'un écoulement bi-dimentionnelle, champ tourbillon est définie comme un champ scalaire porté par la troisième dimension. En particulier dans un repère cartésien $\omega = \frac{\partial v_y}{\partial x} - \frac{\partial v_x}{\partial y}$. De plus le terme d'étirement disparaît $(\bm \omega \cdot \nabla) \bm u$, ainsi les équations lagrangiennes deviennent

\begin{eqnarray*}
    \frac{d \bx_p}{dt} = \bm u(\bx_p, t) \\
    \frac{d\omega}{dt} = \nu \Delta \omega(\bx_p, t)
\end{eqnarray*}

Le champ de vorticité est discrétisé à l'aide d'un ensemble de particules $p$ défini à une position $\bm z_p$, une quantité de circulation locale $\Gamma_p$ qui est par définition la circulation autour de la particule : $\Gamma_p = \oint_{\partial \Omega_p} \bm v = \int_{\Omega_p} \omega dS$. Ainsi, pour tout point $z \in \Omega \subset \mathbb R^2$ la vorticité peut être exprimée comme

\begin{equation*}
    \omega(\bm z, t) = \sum_{i=1}^{N_p} \Gamma_p(t) \phi_\varepsilon(\bm z - \bm z_p(t)),
\end{equation*}où $\phi_\varepsilon$ est le noyau associé à la particule avec une distance de lissage $\varepsilon$.

La vitesse $\bm u$ peut être obtenue en résolvant l'équation de Poisson suivante

\begin{equation*}~\label{eq:poisson}
    \lambda \bm u = - \nabla \times \omega.
\end{equation*}

Finalement, par une représentation intégrale et en choisissant $\phi= \delta$, on obtient dans le cas 2D l'équation de Biot-Savart suivante

\begin{equation*}
    \bm u(\bm z) = \sum_p \frac{\Gamma_p}{2\pi} \frac{(\bm z - \bm z_p)\times \bm k}{\|\bm z - \bm z_p\|^2},
\end{equation*}où $\bm k$ est le vecteur unitaire normal au plan.

En pratique, le choix d'un noyau en Dirac rend ainsi impossible le calcul de la vitesse sur la discrétization particulaire à cause du dénominateur en ${\|\bm z - \bm z'\|^2}$. En choisissant un noyau de type gaussien de taille $\varepsilon$ on obtient alors

\begin{equation*}
    \bm u(\bm z) = \sum_p \frac{\Gamma_p(1 - \exp(-r^2 / \varepsilon^2)) }{2\pi r^2} (\bm z - \bm z')\times \bm k, \quad r = \|\bm z - \bm z'\|.
\end{equation*}

L'idée d'utiliser un noyau de lissage est en cela assez proche de ce qui est fait avec la méthode SPH.

Afin de tenir compte de la diffusion, une approche par fractionnement est généralement utilisé. Introduite pour la première fois par Chorin~\cite{chorin_discretization_1973}, elle permet dans le cas de problème où le terme de transport est dominant, de traiter séparemment et successivement les termes d'advection et de diffusion.

Ainsi après avoir mis à jour la position des particules sans tenir compte de la viscosité, l'équation suivante est résolue

\begin{equation*}
    \frac{d\bm omega_p}{dt} = \nu \Lambda \omega(\bx_p).
\end{equation*}

Pour se faire, deux méthodes sont principalement utilisées : soit la méthode par marche aléatoire introduite dans~\cite{chorin_discretization_1973} ou par échange d'intensité introduite par~\cite{1989MaCom..53..485D}.
Dans le premier cas, la position de chaque particule est perturbée avec un vecteur de variables indépendantes tirées selon une distribution gaussienne de moyenne zero et d'écart-type $2\nu \Delta t$. Dans le second cas, l'opérateur différentiel est approximé à l'aide de la discrétisation comme il est fait dans la méthode SPH. Dans ce dernier cas l'intensité évolue comme

\begin{equation*}
    \frac{d \omega_p}{dt} = \nu \varepsilon^{-2} \sum_q V_q [\omega_q - \omega_p] \phi_\varepsilon(\bx_p - \bx_q).
\end{equation*}

\subsubsection{\textit{Vortex-In-Cell} (VIC)}

La méthode Vortex-In-Cell~\cite{christiansen_1973}, tout comme la méthode MPM~\ref{sec:mpm} est une version \textit{Particle-In-Cell}~\cite{birdsall_1969} de la méthode Vortex précédemment décrite. Elle a été développé pour tenir compte de ses faiblesses. Comme la méthode MPM, celle-ci tient bénéfice de la représentation particulaire des particules pour tenir compte du terme d'advection mais également d'une grille de calcul pour résoudre l'équation de Poisson ou le terme de diffusion en utilisant des méthodes eulérienne.

Le schéma de transfert est similaire d'avec celui de la méthode MPM. D'abord une projection du champ de vorticité sur la grille pour obtenir les valeurs nodales $\omega_I$ à l'aide d'un noyau de redistribution $W_I$

\begin{equation*}
    \omega_I = \frac{1}{V_p}\sum_p \Gamma_p W_I(\bx_p).
\end{equation*}

L'équation de Poisson~\ref{eq:poisson} est résolue sur la grille, soit par différences finies, soit par une méthode FFT pour obtenir des vitesses au noeud $\bm u_I$. La vitesse est ensuite interpolée sur le particule (g2p) pour mettre à jour leur position (advection).

Avec de la diffusion, l'équation de diffusion peut être ensuite résolue sur la grille et interpolé pour mettre à jour les quantités particulaire.

De cette manière l'étape de recherche de plus proche voisin n'est pas nécessaire, la résolution des équations se faisant directement sur la grille.

\subsubsection{Similarité avec les méthodes SPH et MPM}

Contrairement aux méthodes SPH et MPM, la méthode Vortex n'est pas adéquat à la résolution de problème en mécanique des solides par exemple pour la simulation du mélange dans le tambour en rotation. Elle partage un certain nombre de similitudes avec celles-ci.


% Cette approche diffère de la MPM dans le sens où les particules portent des informations complexes sur les propriétés mécaniques du matériau.
formation et l'évolution de tourbillons, tout en maintenant une structure de calcul relativement simple.

\section{Méthodes sans maillage et assimilation de données}

L'assimilation de données, lorsqu'appliquée à des systèmes simulés par la méthode des éléments discrets (DEM), se heurte à plusieurs limites importantes. A la fois pour les méthodes variationnelles (ex : 3DVar) ou stochastique (ex : EnKF) il faut consédérer deux problématiques majeurs : la définition de l'état et la manière de le mettre à jour.

\subsection{Définition de l'état d'une méthode sans maillage}~\label{sec:etat_meshless}

L'état est ce qui permet de représenter l'état du système virtuel.

Les méthodes classiques vont utiliser un maillage fixe pour le définir.

En considérant un domaine $\Omega \subset \mathbb R^d$, soit $\mathcal{T} = (\mathcal N, \mathcal E)$ un maillage, où $\mathcal N = \left\{\bm x_i \right\}^N_{i=1}$ est l'ensemble des noeuds, et $\mathcal{E} = \{ K_j \}_{j=1}^{M}$ l'ensemble des éléments.

L'état de la solution \(u_h\) discrétisé peut alors être définie

\begin{itemize}
    \item sur les nœuds du maillage $\bz = \{ u(\mathbf{x}_i) \}_{i=1}^{N}$, c'est le cas des éléments finis (FEM) ;
    \item  sur les éléments du maillage $\bz = \{ u(K_j) \}_{j=1}^{M}$, c'est le cas des volumes finis (VF).
\end{itemize}

Le maillage étant fixe, il n'est pas nécessaire d'inclure la position des noeuds ou des éléments.

Il est alors possible de définir l'état comme une variable aléatoire et d'exprimer ses statistiques.

Dans le cas des méthodes sans maillage, la situation est différentes. Le support de discrétisation, porté par les particules, évolue au cours du temps. L'état ne peut donc pas être défini uniquement par les valeurs d'intensité, mais doit considérer également les positions.

Une première solution consiste à considérer chaque particules indépendemment dans la définition de l'état.

Pour la DEM, l'état à l'intant $t$, pourrait alors être défini comme

\begin{equation*}
    \bz = {(\bx_i(t), \bm v_i(t), \bm \theta_i, \bm \omega, \mathcal P_i)}_{i=1}^N
\end{equation*}où $N$ le nombre de particules, et présente à la fois les variables cinématiques ainsi que $\mathcal P_i$ les propriétés intrinsèques de la particules comme sa masse ou sa géométrie.

De même pour les méthodes sans maillage continues, par exemple la méthode vortex, l'état peut être défini comme

\begin{equation*}
    \bz = {(\bx_i(t),\bm \Gamma_i(t), \mathcal P_i)}_{i=1}^N
\end{equation*}où cette fois $\mathcal P_i$ défini en particulier les propriétés de la fonction de lissage.

Cette définition de l'état a en particulier été utilisé~\cite{chen_superfloe_2022} pour une méthode DEM appliqué au mouvement de la banquise ou bien avec la méthode vortex~\cite{darakananda_data-assimilated_2018,le_provost_ensemble_2021}. C'est sont des filtres EnKF qui ont été présenté à chaque fois.

Toutefois, cette définition peut difficilement être mise en pratique dans le cas général en particulier pour les méthodes d'ensemble.

Premièrement, il est alors nécessaire de faire l'hypothèse que tous les membres possèdent le même nombre de particules dans un ordre défini.
Dans le cas contraire il n'est pas possible de réaliser le calcul des statistiques sur l'ensemble.

Dans le cas où les membres disposerait d'un nombre de particules différents, il serait possible d'ajouter les particules supplémentaires à la suite des précédentes dans le vecteur d'état en remplissant de valeurs nulles pour les autres membres. Cependants, le risque est de voir le nombre de particules augmenter considérablement.

Cette remarque est d'autant plus sensible en considérant le caractère chaotique d'un problème à N-corps~\ref{poincare1890}. En effet, dans ce cas, deux particules proches à une perturbation près peuvent, en un temps, voir leur trajectoires totalement décorélée~\textcolor{red}{image d'un systeme à n corps}. Le système peut conserver une régularité dans sa globalité, mais il devient tout à fait incongru de continuer à comparer ces deux particules entre elles. Ainsi, il n'est plus possible de définir l'état comme selon une collection de particules individuelles ou bien de définir des statistiques qui est un sens pour une particule données.

Dans les articles~\cite{chen_superfloe_2022} ou \cite{darakananda_data-assimilated_2018} cette première limitation a été traité en regroupant les particules pour en obtenir des systèmes de plus faible dimension. Dans le premier cas, il s'agit de créer des superstructures de glace, dans le second cas, il s'agit d'utiliser des méthodes d'agglomération de vortex.

Néanmoins, ces méthodes réduisent le niveau de détail de la discrétisation. Dans notre cas, nous souhaiterions proposer des méthodes d'assimilation qui ne nécessite pas de réduire la qualité des solutions.

\subsection{Mise à jour de l'état d'une simulation sans maillage}

\subsubsection{Pour les méthodes variationnelles}

Une autre problématique majeur est celle de la mise à jour de l'état lors de l'analyse.
Une première limitation concerne les méthodes variationnelle comme la méthodes 3DVar. Pour ce type de problème, directement l'état à partir des variables particulaires est problématique pour différentes raison. Tout d'abord, l'opérateur d'observation $\mathcal H(z)$, s'il consiste à observer un champ par exemple, est non-linéaire par rapport aux variables particulaires tel que la position $\bx_i$ ou l'orientation $\bm \theta_i$. Pour un système avec des milliers voire des millions de particules, on se retrouve à traiter un problème d'optimisation fortement non-linéaire dans un espace de très grande dimension.

De nouveau, on pourrait procéder à une réduction du nombre de particules comme précédemment.

Toutefois, dans le cas des méthodes discrètes, il est nécessaire de prendre en considération un nombre élevé de contraintes. Notamment, le déplacement des particules doit respecter l'interdiction d'interpénétration des particules. Cette conditions doit être vérifié sur l'ensemble du système pour assurer que la solution d'optimisation soit physiquement admissible. Dans le cas des méthodes continues, les particules sont des entités ponctuelles et ne représente qu'une discrétisation d'un milieu continu. Ainsi cette dernière contrainte ne s'applique.

Finalement, utiliser une méthode d'assimilation de données variationnelles dans le cas d'un problème sans maillage nécessite de traiter une problème d'optimisation non linéaire de grande dimension avec contraintes lorsque le milieu est discret et sans contrainte dans le cas continu.

\subsubsection{Pour la méthode EnKF}

Dans le cas de la méthode EnKF, la mise à jour est définie de manière statistique. L'état estimé du système est une combinaison linéaire des états prédits par les différents membres de l'ensemble, en particulier sur les positions des particules $\bx_i$. Or bien que chaque membre vérifie les conditions de d'interpénétration, ses conditions n'étant pas linéaire, il n'y a aucune garantie pour que la combinaison le soi.
En d'autres terme, la mise à jour ne peut être réalisé que via le solveur lui-même capable de vérifier des contraintes de non interpénétrabilité mais ne peut être réalisé directement. Dans le cas de l'article~\cite{chen_superfloe_2022}, nous supposons que le critère de pénétration est relaxé que pour des simulations de milieux granulaire.

Si toutefois cette problématique ne concerne pas les méthodes sans maillage continu, il reste toutefois questionnable de réaliser une combinaison linéaire des positions des particules. Cette question est en fait en lien avec la définition de l'état.
En effet, chaque particule n'est que le support de la discrétisation d'un champ. Mesurer une erreur quadratique sur la position des particules n'aura pas de véritable avec l'erreur quadratique sur le champ.
Ceci est relativement vrai pour des champs tournant. La figure~\textcolor{red}{rajouter une exemple}, présente un cas où chaque membre discrétise un même champ de tourbillon mais où le support de discrétisation a plus ou moins de retard. L'estimateur sur une grille eulérienne sera bien ce même champ. Or, dans le cas ou ce sont les quantités de la discrétisation qui sont prise en compte dans l'état et l'estimateur ne sera par représentatif.
Encore une fois, une solution consiste à réaliser des agrégations pour regrouper les particules comme en~\cite{chen_superfloe_2022,darakananda_data-assimilated_2018} mais au détriment du détail de discrétisation.

Finalement, la mise à jour en considérant des discrétisations particulaires est complexe. En DEM elle doit prendre en considération les positions relatives des particules entre elles. De manière générale, nous avons vu que considérer les statistiques sur les positions de particules ne permettait pas d'avoir une bonne idée de l'incertitude sur le champ discrétisé.

Ainsi, il nous semble nécessaire de formuler différemment le problème d'assimilation dans le cadre d'un discrétisation particulaire.

\section{Assimilation de données sur maillages adaptatifs}

\textcolor{red}{présenter des méthodes dans des cas où les membres ne partage pas la même discrétisation}

Les méthodes particulaires continues peuvent être considérées comme le choix d'une discrétisation mobile d'un problème continu. Ainsi, en utilisant un ensemble de simulations basées sur ces méthodes, on se heurte aux mêmes problématiques que celles rencontrées avec des simulations utilisant des maillages adaptatifs.
Dans ce cas le principal défi réside dans le fait que les dimensions de l'espace d'état changent au cours du temps et diffèrent d'un membre de l'ensemble à l'autre. Cette variabilité complique les opérations ensemblistes habituelles, telles que les calculs matriciels, lors de la mise à jour de l'analyse.

Une solution courante consiste à adopter une discrétisation de référence commune à tous les membres. Dans les méthodologies à grille fixe avec l'analyse multi-résolution (MRA) et dans les scénarios de maillage mobile, les états définis sur des grilles variées sont harmonisés à travers des techniques de projection et d'interpolation pour établir une grille de référence destinée aux mises à jour des états \cite{siripatana_combining_2019, bonan_data_2017}. Cette démarche offre une grande flexibilité, permettant diverses combinaisons de grilles de référence et de mise à jour adaptées aux spécificités des données et des objectifs de l'étude. Par ailleurs, Siripatana et al. \cite{siripatana_combining_2019} soulignent que la correction par le Filtre de Kalman d’Ensemble (EnKF) repose uniquement sur les prédictions et les observations, indépendamment de la définition de l'état. En réalité, cela simplifie l'application de l'EnKF dans des contextes où les maillages varient entre les membres de l'ensemble en proposant une correction qui est indépendante de la discrétisation



\section{Méthodes d'assimilation pour des données lagrangiennes}
\textcolor{red}{présenter des méthodes dans des cas où les variables sont des quantités lagrangiennes}

D'autre part
- Méthode sans maillage sont des méthodes Lagrangiennes
- Avoir données variable problématique déjà traité par des données océanographiques issu de flotteurs par exemple
- Pour traiter ce type de problème, une première approche initialement développé dans~\cite{ide_2002}, est d'augmenter le vecteur d'état ici noté $\bm x$ avec les données d'observation de position de traceur. Cependant, cette variable étant fortement non-linéaire, l'application d'un filtre de Kalman étendu (linéarisation du filtre de Kalman) ne converge pas si les observaitions ne sont pas suffisemment fréquente. Finalement, cela revient à définir l'état comme dans la Section~\ref{sec:etat_meshless} précédente, ce qui n'est pas adéquat.

L'utilisation d'une méthode de type état augmenté trouve plus de sens pour l'application de méthode variationnel.
C'est en particulier ce qui est proposé dans les travaux de Apte~\cite{apte_2008} pour le filtre 3DVar et le ceux de Nodet~\cite{nodet_2006} pour le filtre 4DVar incrémental.

Cependant, ici les quantités Lagrangiennes sont des quantités passives, c'est à dire qu'elles n'interviennent pas dans la résolution du champ de vitesse à intégrer. Dans notre cas les traceurs sont des supports de discrétisation de la solution. De ce fait, le modèle adjoint du modèle n'est pas aussi simple à construire car la position des particules impactent le champ de vitesse à intégrer.

\section{Bilan du chapitre}

Au travers des précédentes méthodes sans maillage, nous constatons que l'application des méthodes d'assimilation sont innégalement applicable. En particulier, les méthodes discrètes offre difficilement la possibilité de corriger directement l'état de la discrétisation, et nécessite une correction au travers du schémas d'intégration pour éviter des problèmes d'interpénétration. Dans la suite, nous nous focaliserons sur les méthodes sans maillage continues.

D'autre part, les méthodes particulaires continues (par exemple MPM, SPH), permettent une plus grande flexibilité des schémas d'assimilation. En effet, chaque particule est définie en un point, ce qui annule tout problème d'interpénétration.

Dans tous les cas, ce sont des méthodes qui ont la particularité d'avoir des discrétisations variables au cours du temps. Cela vient de la représentation lagrangienne sous jacente. Cela rend difficile l'application de méthodes ensemblistes comme la méthode EnKF ou des opérations de calcul matriciel doivent être réalisé entre membres.

D'autre part, ce sont des méthodes dont les opérateurs d'observation sont hautement non-linéaire par rapport aux positions des particules. Ainsi, cela complexifie l'application de méthodes variationnelles qui doivent construire des modèles adjoints pour des méthodes particulaires de grande taille.

Ainsi il devient assez claire que positions et intensités de particule ne peuvent pas être traité de la même manière. Ainsi en s'inspirant des méthodes d'assimilation sur des maillages adaptatifs ou multi résolution, on proposera des méthodes d'assimilation ensembliste qui mettrons à jour les intensités.

Dans un second temps, on proposera plutôt des approches variationnelles pour traiter de la correction des positions de particule.

Afin de facilité le développement de nouveaux filtres, nous avons utilisé la méthode vortex. Elle a été choisie car elle offre une modélisation plus simple que les méthodes SPH et MPM. En effet, chaque particule ne transporte qu'une quantité scalaire, une quantité de tourbillon. Toutefois, elle dispose de toutes les caractéristiques d'une méthode particulaire continue avec à la fois une formulation classique de la méthode se rapproche de la méthode SPH et la méthode Vortex-In-Cell de la méthode MPM.
