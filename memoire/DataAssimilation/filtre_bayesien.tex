% !TEX root = main.tex

\chapter{Assimilation de Données}
\section{Introduction}~\label{intro_da}

\mycolor{La DA est un processus permettant d'intégrer des informations issues de différentes sources pour obtenir une compréhension plus précise et plus complète d'un système ou d'un phénomène. Cette méthode combine des données observées (mesures réelles) avec des prévisions issues de modèles numériques. L'objectif est de corriger et d'améliorer les modèles en fonction des observations, réduisant ainsi les incertitudes et améliorant la précision des prévisions. Dans ce processus, les observations, qui peuvent être incomplètes ou entachées d'erreurs, sont confrontées aux prévisions du modèle au cours du temps. Le modèle est ensuite ajusté pour mieux correspondre aux données réelles. Il s'agit donc de résoudre un problème inverse en prenant en compte l'aspect dynamique du phénomène. Cette méthode est largement utilisée dans divers domaines tels que la météorologie, l'océanographie, la géophysique, et l'ingénierie environnementale. Par exemple, en météorologie, la DA est essentielle pour les prévisions météorologiques en intégrant des données satellites et des mesures au sol dans les modèles atmosphériques.}

L'assimilation peut être décrit comme la combinaison des informations a priori d'un modèle de simulation numérique avec les données issues de l'observation afin d'obtenir une estimation optimale d'un système dynamique et de ses incertitudes.

L'assimilation de données trouve son origine en prédiction météorologique ou en océanographie \mycolor{citer Bocquet}. Cependant, sa formulation mathématique se base sur l'inférence Bayésienne, la théorie du contrôle et le calcul variationnel.

Plus que l'estimation d'un état, l'assimilation de données est aussi une formulation appropriée pour mettre à jour les paramètres d'un système.

\section{Définition du problème}

Nous décrirons le problème d'assimilation sous sa forme d'inférence Bayésienne. Suivant différentes hypothèses, nous montrerons qu'elle s'exprime alors sous des formes variées.

\subsection{Définition de l'état}
% Définition de l'état initial, modèle d
Nous définissons un état $\bm x_k$ comme la variable d'\textit{état} qui définit complètement l'état du système à l'instant $t_k \in \mathbb R^+$. L'état du système est obtenu grâce un modèle $\mathcal{M}$ qui décrit l'évolution du système.
Nous noterons $\mathcal X_k = \{\bx_0, \dots, \bx_k\}$ la trajectoire du modèle jusq'au pas de temps $t_k$.
Nous supposerons que le modèle admet des incertitudes. Celle-ci sont issues de

\begin{itemize}
    \item L'erreur de discrétisation dans l'espace et le temps. Soit $\bm x^c$ l'état réel continu. Le modèle numérique ne traite que des représentations discrètes du champ physique. Ainsi, c'est non pas l'état $\bm x^c$ qui est estimé mais une projection dans l'espace de discrétisation. Ainsi on estimera $\bm x^t = \Pi(\bm{x}^c)$, où $\Pi$ est un porjecteur sur l'espace de discrétisation. On parle ici d'erreur de représentativité.
    \item L'erreur de modèle. C'est un modèle numérique qui calcule l'évolution de l'état simulé. Tout modèle étant imparfait, toutes les physiques ne peuvent êter prises en compte. C'est une erreur qui tient compte de la mauvaise représentation de l'évolution du système mais également de la discrétisation.
\end{itemize}

Ainsi nous traiterons l'état comme une variable aléatoire tel que à laquelle nous lui associerons une incertitude à la prédiction $\bm \eta_k$

\begin{equation*}
    \bm x_k \mathcal{M}(\bx_0, t_k ; \bm \theta) + \eta_k.
\end{equation*}
où $\bm \theta$ sont l'ensemble des paramètres du modèle et $\bm x_0$ l'état initial.

\subsection{Définition des obervations}
A une formulation dynamique, nous supposons également connue une formule d'émission ou équation d'observation. Celle-ci relie l'état et l'espace de mesure. On définie $\mathcal{D}_k$ les mesures prédites par la fenêtre d'état $\mathcal{X}_k$. Tout comme l'état, les mesures sont sujettent à des incertitudes issues de plusieurs sources

\begin{itemize}
    \item Erreur de mesure. L'observable $\bm y^c$ est issue d'un signal réel fonction de l'état continu $\bm x^c$. Or ce signal est mesuré par une capteur sujet à des erreurs instrumentales $\bm \varepsilon^{mu}$.
    \item Erreur de représentativité. L'observation est prédite par un opérateur d'observation numérique $\mathcal H$ via $\bm x_k$. Ainsi une erreur supplémentaire est induite par la représentation de l'opérateur $\mathcal H$ et celle de la projection de l'état continu avec $\Pi$.
\end{itemize}

En supposant que ces erreurs sont additives, on défini la formule suivante
\begin{equation*}
    \mathcal D_k = \mathcal H (\mathcal{X}_k) + \bm{\varepsilon}_k
\end{equation*} où $\bm{\varepsilon}_k = \bm{\varepsilon}^\mu  + \bm{\varepsilon}^r$ défini l'incertitude sur l'observation $\mathcal D_k$ relatif à la prédiction $\mathcal{X}_k$.

\subsection{Inférence Bayésienne récursive}

Le problème d'assimilation de données peut être formulé sous une approche d'inférence Bayésienne. Celle-ci est une méthode statistique pour estimer l'état $\mathcal X_k$ en utilisant à la fois une information a priori et les données observées. Cette méthode repose sur le théorème de Bayes qui décrit la relation entre la distribution a priori de l'état $p(\mathcal X_k)$, la vraissemblance des données $p(\mathcal D_k \mid \mathcal X_k)$ conditionnellement à l'état et la distribution a posteriori de l'état étant donné les données observées, donnant alors

\begin{equation*}
    p(\mathcal X_k \mid \mathcal D_k) = \frac{(\mathcal D_k \mid \mathcal X_k)~p(\mathcal X_k)}{p(\mathcal D_k)}
\end{equation*}où $p(\mathcal D_k)$  est la distribution marginale des observations. Elle agit comme constante de normalization afin d'assurer que l'intégrale de la distribution a posteriori vaut bien un

\begin{equation*}
    p(\mathcal D_k) = \mathbb E_{\mathcal X_k}[\mathcal D_k \mid \mathcal X_k]
\end{equation*}

Nous souhaitons résoudre le problème d'assimilation de manière séquentielle. C'est à dire, mettre à jour l'état à chaque nouvelle observation à l'instant $t_k$. Pour ce faire, nous utilisons deux approximations

\begin{itemize}
    \item Le modèle dynamique est une chaîne de Markov d'odre 1. Cette hypothèse suppose que l'état futur $\bm x_{k+1}$ est indépendant des états passé $\mathcal X_{k-1}$ conditionnellement à l'état présent $\bm x_{k}$. Le modèle dynamique s'écrit alors

          \begin{equation*}
              \bm x_k \mathcal{M}(\bx_k ; \bm \theta) + \eta_k.
          \end{equation*}

          ce qui implique mathématiquement que
          \begin{equation*}
              p(\bx_{k+1} \mid \bx_{k},\bx_{k-1}\dots \bx_{0}) = p(\bx_{k+1} \mid \bx_{k}).
          \end{equation*}

          Ainsi, la probabilité de l'état $p(\mathcal{X}_k)=p(\{\bx_0, \dots, \bx_k\})$ devient

          \begin{eqnarray*}
              p(\mathcal{X}_k) &=& p(\bx_0) p(\bx_1 \mid \bx_0) p(\bx_2 \mid \bx_1) \dots p(\bx_k \mid \bx_{k-1}) \\
              &=& p(\bx_0) p(\bx_1 \mid \bx_0) \prod_{l = 1}^{k} p(\bx_l \mid \bx_{l_1}).
          \end{eqnarray*}

    \item Les observations sont indépendantes entre chaque assimilation. Cette hypothèse suppose que les observations présentes $\by_k$ est indépendante des états et observations passé conditionnellement à $\bx_k$. Ceci correspond à définir une loi d'émission local
          \begin{equation*}
              \by_k = \mathcal H (\bx_k) + \bm{\varepsilon}_k
          \end{equation*}
          et une vraissemblance comme le produit de vraissemblance locale

          \begin{equation*}
              p(\mathcal{D}_k \mid \mathcal Z_k) = \prod_{l=1}^{k} p(\by_l \mid \bx_l)
          \end{equation*}
\end{itemize}

Ainsi la trajectoire de l'état et des observation suis les hypothèses d'un modèle de Markov cachés, ici à temps discret, et qui peut être schématisé par le schéma Figure \ref{fig:hidden_markov}.

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.5\textwidth]{chemin/vers/ton/image}
    \caption{Chaîne de Markov cachée \mycolor{Mettre un graph Bayésien}.}
    \label{fig:hidden_markov}
\end{figure}

\subsection{Estimation des paramètres du modèle par augmentation de l'état}
Nous avons supposé que le système était complètement décrit par la variable d'état $\bx$ que nous souhaitons estimé. Cependant, nous avons aussi supposé que le modèle était imparfait car ne modélisant pas toute la physique de la dynamique mais parce que les paramètres du modèle $\theta$ ne sont pas connu avec certitude. L'estimation ou calibration de ces paramètres est possible en définissant un état augmenté $\bm z = (\bx, \bm \theta)$.

Le modèle d'évolution est toutefois différent car les paramètres du modèle sont supposé constant dans le temps tel que

\begin{gather*}
    \left\{\begin{aligned}
         & \bm{x}_{k+1}      & = & \mathcal{M}(\hat{\bm{x}}_{k}) + \bm{\eta}_{k+1}    & , \\
         & \bm{y}_{k+1}      & = & \mathcal{H}(\bm{x}_{k+1}) + \bm{\varepsilon}_{k+1} & , \\
         & \bm{\theta}_{k+1} & = & \bm{\theta}_{k+1} + \bm{\xi}_{k+1}                 & .
    \end{aligned} \right.
\end{gather*}

L'ajout des paramètres dans la variable d'état a pu être utilisé pour résoudre des problème inverse sans avoir besoin sans calcul de gradient~\cite{iglesias_ensemble_2013}.

\section{Filtrage bayésien}~\label{filtrage_bayesien}

Le filtrage bayésien consiste à écrire la récurrence sur les lois de probabilité, pour estimer, en fonction des observations passées et courante $y_{1:k}$ l'état courant $\bm x_k$ et de prédire l'état future $\bm x_{k+1}$.

Pour simplifier les notations, l'exposant $^{\mid k}$ qui conditionne la densité par les observations $\bm y_{1:N}$.
La densité de l'état est initialisée par la densité a priori de l'état initial $p_{X_0}$.

Puis pour tout $k \geq 0$ les lois de probabilité sont propagées.

L'étape de propagation ou \textit{forecast} loi \textit{a priori} est obtenue grace à la loi des probabilité totales

\begin{equation}\label{tot_rule}
    p_{\bm X_{k+1}}^{\mid k}(\bm x)= \int p_{\bm X_{k+1}\mid \bm X_{k} = \bm x'}(\bm x) p_{\bm X_{k}}^{\mid k}(\bm x')dx'
\end{equation}

La loi \textit{a priori} de la $k+1$ observations peut être otenue de nouveau grace à la loi de probabilité totale

\begin{equation*}
    p_{\bm Y_{k+1}}^{\mid k}(\bm y) = \int p_{\bm Y_{k+1}\mid \bm X_{k+1} = \bm x}(\bm y) p_{\bm X_{k+1}}^{\mid k}(\bm x)dx
\end{equation*}

Après la $k+1$ observation $\bm y_{k+1}$, l'étape d'\textit{analyse} permet de déterminer la loi \textit{a posteriori} de l'état
avec la loi de Bayes appliquées après mesure de $\bm Y_n$

\begin{equation*}
    p_{\bm X_{k+1}}^{\mid k+1}(\bm x) = p_{\bm X_{k+1} \mid \bm Y_{k+1} = \bm y_{k+1}}^{\mid k}(\bm x) = \frac{p_{\bm Y_{k+1} \mid \bm X_{k+1} = \bm x}^{\mid k}(\bm y) p_{\bm X_{k+1}}^{\mid k}(\bm x) }{p_{\bm Y_{k+1}}^{\mid k}(\bm y)}.
\end{equation*}

la loi de Bayes après mesure de $\bm Y_n$

\section{Filtre particulaire}~\label{filtre_particulaire}

Le filtre particulaire est une implémentation du filtre bayésien qui approxime la PDF à l'aide d'une distribution empirique. Les transformations du filtre, \textit{forecast} et \textit{analysis} sont appliquées sur les membres de cet échantillon.
Cette méthode converge vers la distribution exacte lorsque le nombre de particule $N \to \infty$.

Le prior de l'état $p(\bm x)$ à l'instant $k$ est représenté par un ensemble de $N$ réalisations $\{\bm x_1, \bm x_2, \dots \bm x_N\}$ de tel sorte que

\begin{equation*}
    p_{\bm X_k}(\bm x) \simeq \sum_{i=1}^N \omega^i_k \delta(\bm x - \bm x_k^i) \quad \text{with} \sum_{i=1}^N \omega^i_k = 1, \quad \omega^i_k > 0.
\end{equation*}

où $\delta$ est la masse de Dirac et $\omega^i_k$ les poids associés à chaque membre. Initialement, les échantillons sont supposés tirés de manière uniforme de tel sorte que $\omega^i_k = 1/N$.

Lors de l'étape de \textit{propagation}, les particules sont propagés par le modèle de manière déterministe.

Pour s'en convaincre, le loi de probabilité totale \ref{tot_rule} peut être réécrite

\begin{eqnarray*}
    p_{\bm X_{k+1}}^{\mid k}(\bm x) &=& \int p_{\bm X_{k+1}\mid \bm X_{k} = \bm x'}(\bm x) p_{\bm X_{k}}^{\mid k}(\bm x')dx' \\
    &\simeq& \int p_{\bm X_{k+1}\mid \bm X_{k} = \bm x'}(\bm x) \sum_{i=1}^N \omega^i_k \delta(\bm x' - \bm x_k^i) dx' \\
    &\simeq& \sum_{i=1}^N \omega^i_k  \int p_{\bm X_{k+1}\mid \bm X_{k} = \bm x'}(\bm x) \delta(\bm x' - \bm x_k^i) dx' \\
    &\simeq& \sum_{i=1}^N \omega^i_k \delta(\bm x - \mathcal M_{k,k+1}(\bm x_k^i) - \bm \eta_{k,k+1}) = \sum_{i=1}^N \omega^i_k \delta(\bm x - \bm x_{k+1}^i).
\end{eqnarray*}

Quant à l'étape d'analyse, elle correspond à une mise à jour du poids de chaque membre, qui correspond à sa vraissemblance conditionnée aux données

\begin{eqnarray*}
    p_{\bm X_{k+1}}^{\mid k+1}(\bm x) &\propto& p_{\bm Y_{k+1} \mid \bm X_{k+1} = \bm x}^{\mid k}(\bm y)  \sum_{i=1}^N \omega^i_k \delta(\bm x - \bm x_{k+1}^i) \\
    &\propto& \sum_{i=1}^N  \omega^i_k~p_{\bm Y_{k+1} \mid \bm X_{k+1} = \bm x_{k+1}^i}^{\mid k}(\bm y)\delta(\bm x - \bm x_{k+1}^i)
\end{eqnarray*}

Leading to

\begin{equation*}
    \omega^i_{k+1}  = \frac{\omega^i_k~p_{\bm Y_{k+1} \mid \bm X_{k+1} = \bm x_{k+1}^i}^{\mid k}(\bm y_{k+1}) }{\omega^j_k~\sum_j^N p_{\bm Y_{k+1} \mid \bm X_{k+1} = \bm x_{k+1}^j}^{\mid k}(\bm y_{k+1}) }
\end{equation*}

Où le dénominateur est simplement un terme de normalisation.

Cependant, lorsque la dimension est grande, le nombre de poids non nulle à tendance à tendre vers 0. Pour éviter cela, des méthodes de rééchantillonnage du \textit{posterior} ont été développé. Le filtre bootstrap \cite{gordon_1993} consiste à selectionner les membres de poids les plus élevé, de les cloner de manière proportionnelle à leurs poids. Après échantillonnage, $N$ particules sont rassemblées, dont certaines sont identitiques avec des approximativement égaux.
Un exemple d'algorithme suivant

\begin{algorithm}
    \caption{Implémentation du rééchantillonnage par \textit{bootstrap}.}
    \For{membre $n$ do}{
    Tirer $u$ dans $\mathcal{U}[0,1[$\;
    Initialiser $j=1$\;
    Affecter $S_w = w^1$\;
    \While{$S_w < u$}{
        $j = j+1$\;
        $S_w = S_w + w(j)\;$
    }
    Le membre $j$  est conservé et remplace le membre $n$.
    }
\end{algorithm}

\section{Estimation du maximum a posteriori}

La loi a posteriori précédemment défini peut permettre de déterminer l'estimateur MAP (\textit{Maximum A Posteriori}). Il est la meilleure estimation de l'état connaissant les données mesurées. Il est défini comme

\begin{equation*}
    \bm x_{\text{MAP}} = \argmax_{\bm x} p(\bm x \mid \bm y).
\end{equation*}

Cette estimateur peut directement être estimé en suivant complètement la distribution comme dans le filtre particulaire~\ref{filtre_particulaire}.
Autement, une manière de déterminer cet estimateur est d'introduire que la distribution a priori de l'état et des observations sont Gaussiennes.

Nous supposerons donc ici que les variables aléatoire introduites dans la section précédentes sont définies comme

\begin{eqnarray*}
    \bm \eta &\sim& \mathcal{N}(\bm 0, P), \quad p(\bm x) = \mathcal{N}(\bm x^f, P)\\
    \bm \varepsilon & \sim & \mathcal N(\bm 0, R), \quad \quad p(\bm x) = \mathcal{N}(\bm , R)\\.
\end{eqnarray*}

Ainsi la distribution a posteriori peut être réécrite comme

\begin{equation*}
    p(\bm x \mid \bm y) \propto \exp\left(- \mathcal{\L}(\bm x)\right),
\end{equation*}

avec $\mathcal L(\bm x)$

\begin{equation*}
    \mathcal L(\bm x) = \frac12 \norm(\bm x - \bm x^f)_{P^{-1}} + \frac12 \norm{\bm h(\bm x) - d}_{R^{-1}}.
\end{equation*}

De plus, le logarithme étant une fonction strictement croissante, la maximisation de la posterior est équivalente à minimiser $\mathcal L$. D'où la nouvelle expression de $\bm x_{\text{MAP}}$

\begin{equation*}
    \bm x_{\text{MAP}} = \argmin_{\bm x} \mathcal L(\bm x).
\end{equation*}

Cette définition de l'estimateur nous permet d'introduire un ensemble de méthode variationnelles pour l'assimilation de données.
Le minimum de cette fonction peut être obtenue en annulant son gradient

\begin{equation*}
    \nabla  L(\bm x_{\text{MAP}}) = \bm 0.
\end{equation*}

On peut ainsi faire plusieurs remarque

\begin{itemize}
    \item La dérivée seconde de la fonction coût $\mathcal L$, la Hessienne, est une approximation à l'ordre 1 de la matrice de covariance a posteriori,
    \item Si l'opérateur d'observation $h$ est non linéaire alors, le problème n'est pas convexe et une méthode itérative de minimisation est souvent mis en place. Même dans le cas où $h$ est linéaire, le stockage de matrice de grande dimension peut encourager à utiliser ces méthodes.
\end{itemize}


% Dans les prochaines sections, nous présenterons des méthodes qui utiliserons 
\section{Méthode Variationnelle}

La méthode **3D-Var** (Three-Dimensional Variational Data Assimilation) est une méthode statique d'assimilation de données. Elle se concentre sur un seul instant, sans prendre en compte l'évolution temporelle du système. La fonction coût $J_{3D}(x)$ pour le 3D-Var est formulée comme suit :

$$J_{3D}(x) = \frac{1}{2}\|x-x_b\|_{B^{-1}}^2+ \frac{1}{2}\|y-H(x)\|^2_{R^{-1}}$$

où $x$ représente l'état du système, $x_b$ l'état de base ou ébauche (prévision du modèle), $B$ la matrice de covariance des erreurs de prévision, $y$ les observations, $H$ l'opérateur qui relie l'état du système aux observations, et $R$ la matrice de covariance des erreurs d'observation.

Dans la méthode 3D-Var, la minimisation de $J(x)$ conduit à un état optimal qui est une meilleure estimation de l'état réel du système à un instant donné, en tenant compte à la fois des erreurs dans les observations et dans la prévision du modèle.

La méthode **4D-Var** (Four-Dimensional Variational Data Assimilation) étend la méthode 3D-Var en incorporant une dimension temporelle. Cette approche considère non seulement l'état actuel du système mais aussi son évolution dans le temps. Elle cherche à minimiser la fonction coût sur une fenêtre temporelle, prenant en compte les observations et les prévisions à différents moments.

Dans la méthode 4D-Var, la fonction coût est similaire à celle du 3D-Var, mais elle intègre l'aspect dynamique du système. La minimisation de la fonction coût $J_{4D}(x)$ sur une fenêtre temporelle conduit à un ajustement des prévisions du modèle non seulement à un instant donné mais sur toute la période considérée. La fonctionnelle s'écrit

$$J_{4D}(x) = \frac{1}{2}\|x_0-x_{b,0}\|_{B^{-1}}^2 + \frac{1}{2} \sum_{t=0}^T \|y_t-H(x_t)\|^2_{R^{-1}}$$

La résolution du problème d'optimisation associée à l'approche 4D-Var pose une difficulté quant à la résolution du problème numérique. Celle-ci est résolue par un solveur itératif qui nécessite la modélisation et résolution d'un problème adjoint. Cette mise en oeuvre peut se révéler particulièrement fastidieuse.

Les méthodes 3D-Var et 4D-Var présentent une limitation notable : elles ne prennent pas en compte les incertitudes sur l'état assimilé. Dans ces approches, l'accent est mis sur la minimisation de la différence entre les observations et les prédictions des modèles, mais sans une estimation explicite ou une gestion des incertitudes associées à l'état du système après assimilation. Ce point peut impacter la confiance des prévisions.

\section{Filtre de Kalman}

\subsection{Loïc redaction}

Le filtre de Kalman est une méthode algorithmique efficace pour estimer l'état d'un système dynamique en présence d'incertitudes. Il est largement utilisé dans divers domaines tels que le contrôle de processus, la navigation et le traitement du signal. Le filtre de Kalman est une approche séquentielle permettant de mettre à jour l'état estimé au cours du temps, au fur et à mesure que les observations sont collectées.

L'une des hypothèses fondamentales du filtre de Kalman est la linéarité. Le système est supposé être décrit par des équations linéaires, tant pour l'évolution de son état que pour la relation entre les mesures et l'état du système. Cette hypothèse de linéarité est cruciale pour l'application directe du filtre de Kalman, car elle simplifie significativement les calculs impliqués.

Une autre hypothèse clé est que les erreurs, à la fois dans le processus et dans les mesures, suivent une distribution gaussienne. Cette hypothèse permet de décrire entièrement l'incertitude par la moyenne et la covariance, rendant le traitement des incertitudes soluble.

L'équation du filtre de Kalman peut être présentée en deux étapes principales: la **prédiction** et la **mise à jour**. Dans la phase de **prédiction**, l'état actuel du système est estimé à partir de son état précédent. On prédit l'état futur à partir du code de calcul noté $F$ pour "Forward" :
$$
    \begin{aligned}
        x^{f} & = F x^{a},             \\
        P_k^f & = F P_{k-1}^a F^T + B,
    \end{aligned}
$$
où $x^f$ est l'estimation de l'état à l'instant $k$ sachant l'information jusqu'à l'instant $k-1$, et $P_k^f$ est la covariance de l'estimation de l'erreur. $B$ est la covariance du bruit du processus. Les indices $f$ et $a$ indiquent respectivement les états prédits ("forecast") et assimilés ou analysés.

Dans la phase de mise à jour, l'estimation est affinée à l'aide des nouvelles mesures :
$$
    \begin{aligned}
        K     & = P_k^f H^T (H P_k^f H^T + R)^{-1} \\
        x^a   & = x^f + K (y - H x^f)              \\
        P_k^a & = (I - K H) P_k^f
    \end{aligned}
$$
Ici, $K$ est le gain de Kalman, $y$ est la mesure à l'instant $k$, $H$ est la matrice qui relie l'état aux mesures, $R$ est la covariance du bruit de mesure, et $I$ est la matrice identité. $P_k^a$ est la covariance mise à jour de l'erreur d'estimation.

En résumé, le filtre de Kalman fournit une méthode systématique pour intégrer de manière optimale les informations issues des mesures et des modèles dans des systèmes linéaires et gaussiens, offrant ainsi des estimations précises de l'état des systèmes dynamiques. Tout en fournissant une estimation de l'état d'un système, intègre intrinsèquement les incertitudes associées à cette estimation à travers la matrice de covariance $P_k^a$, reflétant ainsi la variabilité et l'imprécision inhérentes aux données et au modèle utilisé.

\subsection{My redaction}

Le filtre de Kalman introduit en 1960 \cite{kalman_new_1960} est une version du filtre Bayésien appliqué à un modèle linéaire Gaussien. Dans ces conditions, la distribution de l'état a priori de l'état et des observations sont défini par leur deux premiers moment tel que la propagation devient

\begin{eqnarray*}
    \hat m_X &=& \bE [\bm X_{k+1}^{\mid k}] = \bm M \bE [\bm X_{k}^{\mid k}],\\
    \hat{\bm  P}_{k+1} &=& \bV [\bm X_{k+1}^{\mid k}] = \bm M \bE [\bm X_{k+1}^{\mid k}] \bm M^T + \bm Q,
\end{eqnarray*}

et le modèle d'observation donne

\begin{eqnarray*}
    m_Y &=& \bE [\bm Y_{k+1}^{\mid k}] = \bm H \bE [X_{k+1}^{\mid k}],\\
    \bm C_{Y,Y}&=&\bV [\bm Y_{k+1}^{\mid k}] = \bm H \bV [\bm X_{k+1}^{\mid k}] \bm H^T + \bm R, \\
    \bm C_{X,Y} &=& \bC[\bm X_{k+1}^{\mid k},\bm Y^{\mid k}_{k+1}] = \bm P_{k+1} \bm H^T,
\end{eqnarray*}

De telle sorte que la distribution conditionnelle de $\bm Y_{k+1}$ par $^{\mid k}$ et $\bm Y_{k+1} = \bm{y_{k+1}}$, si cette dernière est non-dégénérée (ce qui est le cas si $\bm R$ n'est pas singulière), est défini par ses deux premiers moments qui sont
\begin{eqnarray*}
    m_X &=& \bE[\bm X^{\mid k}_{k+1} \mid \bm Y_{k+1}^{\mid k}] = \hat m_X + \bm C_{X,Y} \bm C_{Y,Y}^{-1} (\bm y_{k+1} - m_Y), \\
    \bm P_{k+1} &=& \bV[\bm X^{\mid k}_{k+1} \mid \bm Y_{k+1}^{\mid k}] = \hat{\bm  P}_{k+1} - \bm C_{X,Y} \bm C_{Y,Y}^{-1} \bm C_{X,Y}^T.
\end{eqnarray*}

Ainsi la distribution a posteriori est défini comme un produit matriciel où l'estimateur a priori $\hat m_X$ et sa variance $\hat{\bm  P}_{k+1}$ sont mis à jour à partir du \textit{gain de Kalman} $\bm K = \bm C_{X,Y} \bm C_{Y,Y}^{-1} $ et du \textit{terme d'innovation} $(\bm y_{k+1} - m_Y)$ de telle sorte que les précédentes équations s'écrivent

\begin{eqnarray*}
    m_X &=& \hat m_X + \bm K (\bm y_{k+1} - m_Y), \\
    \bm P_{k+1} &=& (\bm I - \bm K\bm H)\hat{\bm  P}_{k+1} \\.
\end{eqnarray*}

Finalement, on peut réécrire
\begin{algorithm}
    \caption{Filtre de Kalman}
    \KwData{Initialisation de l'état $m x$ et de sa covariance $\bm P$;}
    \For{$k \geq 1$}{
        Prédiction\;
        $\hat m_x = \bm M m x $\;
        $\hat{\bm  P} = \bm M \bE [\bm X_{k+1}^{\mid k}] \bm M^T + \bm Q$\;
        Observation de $\bm Y \to \bm y$
        Analyse\;
        Calcul du gain de Kalman: $\bm K = \hat{\bm{P}}\bm H^T (\bm H \hat{\bm  P}\bm H^T + \bm R)^{-1}$ \;
        Calcul de l'analyse\;
        $m_x = \hat m_x + \bm K (\bm y - \bm H \hat m_x)$\;
        Calcul de la matrice de covariance de l'état\;



    }
\end{algorithm}

\section{Filtre de Kalman d'Ensemble (EnKF)}

Pour surmonter les limitations du filtre de Kalman classique et du filtre particulaire, le filtre de Kalman d'ensemble (EnKF) a été développé. L'EnKF est une méthode d'assimilation de données qui utilise un ensemble de prévisions pour estimer l'état et les incertitudes d'un système. Contrairement au filtre de Kalman classique, qui est optimal pour des systèmes linéaires et des erreurs gaussiennes, l'EnKF est plus robuste quant aux non-linéarités et aux distributions non gaussiennes.

L'EnKF fonctionne en générant un ensemble de prévisions  (ou états) $(x_i^f)_{i=1}^N$ à partir du modèle. Chaque membre de l'ensemble est ensuite mis à jour indépendamment en utilisant les observations disponibles. Les équations de l'EnKF peuvent être présentées comme suit :

- **Étape de Prédiction** :
$$x_i^f = F(x_i^a),$$
où $x_{i}^{f}$ est la prévision du i-ème membre de l'ensemble, et $M$ est le modèle du système.

- **Étape de Mise à Jour** :
$$x_{i}^{a} = x_{i}^{f} + K(y_{i} - h_i^f),$$
avec $K$ le gain de Kalman, calculé comme :
$$K = \text{cov}(x^f, h^f)(\text{cov}(h^f, h^f) + R)^{-1}$$
où $\text{cov}$ est l'opérateur de covariance, $(h_i^f)_{i=1}^N$ est l'ensemble d'observations prédites, et $R$ est la covariance du bruit de mesure.

Dans l'EnKF, $x_{i}^{a}$ est l'état analysé (ou mis à jour) pour le i-ème membre de l'ensemble, et $y_i$ représente les observations. Cette méthode permet de capturer la distribution de probabilité de l'état du système de manière plus efficace et avec moins de charge de calcul que le filtre particulaire, surtout dans les systèmes de grande dimension.

Cette version de l'EnKF est parfois appelé EnKF stochastique car les observations $y_i$ correspondent aux données mesurées bruitées, i.e. $y_i = y + \varepsilon_i$ où $\varepsilon_i$ correspond au bruit de mesure. Ce bruit numérique permet de supprimer un biais statistique sur l'estimation de l'état.

