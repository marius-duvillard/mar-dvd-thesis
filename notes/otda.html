<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Assimilation with field alignment</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="otda_files/libs/clipboard/clipboard.min.js"></script>
<script src="otda_files/libs/quarto-html/quarto.js"></script>
<script src="otda_files/libs/quarto-html/popper.min.js"></script>
<script src="otda_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="otda_files/libs/quarto-html/anchor.min.js"></script>
<link href="otda_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="otda_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="otda_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="otda_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="otda_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
</head><body class="fullcontent">\usepackage{bm}
\newcommand{\norm}[1]{\|#1\|}
\newcommand{\bq}{\bm{q}}
\newcommand{\br}{\bm{r}}
\newcommand{\bs}{\bm{s}}

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>





<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Data Assimilation with field alignment</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Assimilation de données pour les simulations particulaires</p>
<p>L’assimilation de données consiste à combiner les simulations issues d’un modèle avec les données bruités issues de l’observation. Cette cmbinaison nécessite de pouvoir mettre à jour de manière optimal l’état de la simulation en tenant compte par exemple de l’erreur a priori de modèle ainsi que l’erreur d’observation. Cette correction est classiquement appliqué sur les intensités des champs de l’état. Cependant, cette correction se trouve faussé par ce que l’on appelle l’effet de double pénalisation. Cela se produit lorsque les erreurs du modèle et des données observationnelles sont surpénalisées, compromettant l’équilibre nécessaire. Par exemple, un léger déplacement de polluants peut entraîner des prédictions élevées là où aucun polluant n’est observé (voir image), créant des difficultés d’évaluation du modèle. Cette erreur est répandue dans les géosciences, affectant la prévision météorologique, la chimie atmosphérique, la prévision océanique, etc. L’utilisation de l’erreur quadratique moyenne aggrave ce problème, entravant l’apprentissage efficace des modèles. C’est une composante dominante à l’erreur de représentativité. La mise à jour de la DA classique peut être limitée à l’espace des valeurs des champs, ce qui entraîne une analyse confinée aux limites d’ébauche et des observations. Ceci devient une lacune majeure lorsque le désaccord entre les observations et l’état de fond résulte d’une erreur de localisation des champs ou d’une mauvaise spécification générale de ces champs. La Figure 2 illustre des expériences de DA classique avec des analyses bénéfiques et inutiles.</p>
<p>L’objectif de approches qui vont suivre vont avoir pour but de présenter des méthodes d’interpolation non pas dans l’espace euclidien des intensités mais plutôt dans un espace interpolant qui puisse prendre en compte un déplacement dans l’espace physique.</p>
<p>On peut considérer que l’erreur provient du choix du MSE comme mesure d’erreur, qui est une mesure localisé à une position. Une mesure plus intelligente consiste en la combinaison d’une carte de déplacement suivi de la norme classique MSE (Hoffman et al., 1995; Keil and Craig, 2009). Des métriques basées sur des approches on pu être proposées. Une approche élégante consiste à appliquer la théorie du <em>transport optimal</em> qui est associée à la <em>distance de Wasserstein</em>. Des exemples d’utilisation d’OT peuvent être trouvé chez <em>Farchi et al.&nbsp;(2016)</em> et <em>Vanderbecken et al.&nbsp;(2023)</em>.</p>
<p>Si le transport optimal semble l’approche la plus générale capable de répondre à cette problématique, on trouve également différentes formulation capable de prendre en compte l’erreur de double pénalisation. En particulier, les travaux de <em>Ravela (2007)</em>, <em>Percival (2008)</em> ou <em>Rosenthal (2018)</em>.</p>
<section id="field-alignment-displacement-assimilation" class="level1">
<h1>Field alignment / Displacement assimilation</h1>
<p>Ravella introduit dans son papier</p>
<p><em>Ravela, Sai, Kerry Emanuel, et Dennis McLaughlin. «&nbsp;Data Assimilation by Field Alignment&nbsp;»</em></p>
<p>Une méthode pour tenir compte des erreurs de position en appliquant un déplacement à imposer. La méthode est réalisée en deux étapes. D’abord la détermination d’un champ de déplacement, puis la correction des intensités. L’avantage de cette méthode, et quelle est adaptable à de nombreux filtres, en particulier les filtres d’ensemble.</p>
<p>Il présente tout d’abord en quoi la formulation classique dans un problème de position entraîne une inflation de la matrice de covariance. La matrice issue de la perturbation d’une translation <span class="math inline">\(\lambda\)</span> devient: <span class="math inline">\(C_{\lambda} = C_{XX} + \sigma^2_{\lambda} C_{\Delta\Delta}\)</span> où <span class="math inline">\(\Delta\)</span> est la déviation du gradient (8).</p>
<p>Pour réaliser l’alignement, on part de la formule de Bayes comme pour les filtres d’intensité. Cependant, on introduit une nouvelle variable spatiale <span class="math inline">\(\bq\)</span> vecteur de déplacement. Dans leur travail l’état est défini sur une grille dont les positions sont <span class="math inline">\(\br\)</span>. L’état est donc défini par les valeurs du champ <span class="math inline">\(X = X(\br)\)</span>.</p>
<p>On défini <span class="math inline">\(\bq\)</span> sur la même grille tel que <span class="math inline">\(X(\br - \bq)\)</span> est le déplacement de X par <span class="math inline">\(\bq\)</span>.</p>
<p>On réécrit la formule de Bayes en introduisant cette nouvelle variable</p>
<p><span class="math display">\[
P(X, \bq \mid Y) \propto P(Y \mid X, \bq) P(X^f \mid \bq) P(\bq)
\]</span></p>
<p>La Likelihood <span class="math inline">\(P(Y \mid X, \bq)\)</span> est similaire à la likelihood sur les intensités mais en appliquant au préalable le déplacement de telle sorte que les observations sont conditionnées par <span class="math inline">\(X(\br - \bq)\)</span>.</p>
<p>On suppose donc que <span class="math inline">\(Y = H(X(\br - \bq)) + \bm{\eta} \sim \mathcal{N}(0, R)\)</span>, où les observations restent bien fixes.</p>
<p>De même le prior sur l’intensité est inchangé en considérant au préalable la transformation <span class="math inline">\(\bq\)</span>. Mais il faut remarquer que la matrice de covariance est dépendante de <span class="math inline">\(\bq\)</span>. Dans un cas de filtre d’ensemble il s’agit de calculer la matrice également après transformation.</p>
<p>Finalement le prior sur le déplacement <span class="math inline">\(P(\bq)\)</span> est l’élément aditionnel. Pour cela on introduit une fonction d’énergie, qui va régulariser les déplacements. C’est elle qui introduit un coup de déplacement. On peut penser le champ de déplacement comme un champ d’écoulement lissé. Cette propriété de lissage amene donc à considérer des pénalisations de Tikhonov qui va pénaliser à la fois le gradient et la divergence. Mais on peut tout à fait modifier notre a priori sur la distribution de <span class="math inline">\(\bq\)</span>. La prendre uniform n’apporterait pas d’information, la prendre gaussienne demande de définir une manière appropriée pour la définir. La contrainte ici reste locale mais elle introduit une forte régularité par pénalisation.</p>
<p>En prenant finalement la log likelihood on obtient la fonction de coût associée <span class="math inline">\(J(X, \bq)\)</span>. On remarquera que un terme inhabituel lié à la dépendance de <span class="math inline">\(P\)</span> à <span class="math inline">\(\bq\)</span>. On note par la suite <span class="math inline">\(\bp = \br - \bq\)</span> où <span class="math inline">\(\br\)</span> est la coordonnées dans l’espace non déformé.</p>
<p>Ainsi on obtient</p>
<p><span class="math display">\[
J_2(X, \bq) = \frac12 \norm{(X - X^f)(\br - \bq)}^2_{P(\bq)} + \frac12 \norm{Y - H(X(\br - \bq))}^2_{R} + L(\bq) + \frac12 \ln{|B(\bq)|}.
\]</span></p>
<p>Pour résoudre le problème on a besoin de <span class="math inline">\(P(\bq)\)</span> et dériver toute la fonction coût. On peut utiliser pour cela un ensemble comme en EnKF pour l’estimer. Pour cela on suppose connu les déplacements associés à chacun des membres <span class="math inline">\(\bq_s\)</span>. On note <span class="math inline">\(\bp_s = \br_s - \bq_s\)</span>. et on estime donc <span class="math inline">\(B_Q\)</span>. Finalement, on finit par avoir une version Hybrid de la fonction de coût.</p>
<p>Il choisis également de fixer les déplacement dans l’évaluation de <span class="math inline">\(B_Q\)</span> pour éviter de devoir les différentier et modifier dans la version itérative. Il peut ainsi définir les gradients en fonction de <span class="math inline">\(\bq_s\)</span>.</p>
<p>Une autre proposition consiste à séparer la phase d’alignement et de correction des intensités, c’est la méthode séquentielle. Pour cela, à partir de la fonction de cout, on écrit les équation d’Euler-Lagrange. On écrit la fonction de coût différentiée selon <span class="math inline">\(\bq\)</span> puis selon <span class="math inline">\(\bX\)</span>. Je note implicitement <span class="math inline">\(s\)</span> en indice car cela est réalisé parallèlement sur l’ensemble.</p>
<p><span class="math display">\[
\begin{align}
\frac{\partial J_s}{\partial \bq} = (\nabla X \mid_\bp - \nabla X^f \mid_\bp)^T B_Q^{-1} (X(\bp) - X^f(\bp)) + \nabla X \mid_\bp H^T R^{-1} (H X(\bp) - Y) + \frac{\partial L}{\partial \bq} = 0 \\
\frac{\partial J_s}{\partial X} =  B_Q^{-1}  (X(\bp) - X(\bp)) + H^T R^{-1} (H X(\bp) - Y) = 0.
\end{align}
\]</span> On commence par fixer <span class="math inline">\(X\)</span> à <span class="math inline">\(X^f\)</span> dans la première équation, ainsi que <span class="math inline">\(Q\)</span> ce qui permet d’obtenir</p>
<p><span class="math display">\[
\frac{\partial L}{\partial \bq} + \nabla X \mid_\bp H^T R^{-1} (H X(\bp) - Y) = 0
\]</span></p>
<p>Le choix de pénaliser la divergence de <span class="math inline">\(q\)</span> permet d’obtenir une équation de Poisson à résoudre avec un terme source non linéaire. Il propose de résoudre avec une méthode type BFGS. Après essais en utilisant l’autodifférentiation, je constate que ce sont des problèmes fortement non linéaire. Dans la litérature une approche multiéchelle de cette méthode a été proposée. De cette manière le déplacement appliqué est une composition de mode avec plus ou moins de rafinement. D’après moi cela devrait améliorer la convergence.</p>
<p>Finalement, la deuxième étape consiste à résoudre la seconde équation à <span class="math inline">\(\bq\)</span> fixé. On peut réévaluer <span class="math inline">\(B_Q\)</span>. On remarque que l’on obtient la même mise à jour qu’avec un Kalman. Avec la formule SMW on obtient la correction de l’intensité <span class="math inline">\(X\)</span> comme combinaison linéaire du forecast et de l’innovation.</p>
</section>
<section id="rosenthal" class="level1">
<h1>Rosenthal</h1>
<p>Les travaux de Rosenthal ont des similarités avec les travaux de Percival.</p>
</section>
<section id="bridging-data-assimilation-and-optimal-transport" class="level1">
<h1>Bridging data assimilation and optimal transport</h1>
<p>Dans cette partie nous reprenons ce qui existe en terme d’utilsation de l’OT pour l’assimilation de données. Cela se base sur différents articles et thèse. Tout d’abord l’article de <em>Bocquet et al.&nbsp;2023</em> qui présente l’OTDA comme des approches interpolante en déplacement dans l’état physique tandis que les approches classiques vont interpoler dans l’espace des intensités.</p>
<p>Il y a ensuite les travaux de Feyeux pour qui utilise une distance de Wasserstein pour l’assimilation de données issues d’images.</p>
<p>Egalement les travaux de Ravela 2007 peuvent trouver une résonnance dans une approche OT via une étape d’alignement de champs.</p>
<p>Un travail de W.Steven Rosenthal Displacement data assimilation et al.&nbsp;2017 trouve de similarités avec notre problématique de Vortex.</p>
<section id="bocquet-marc-pierre-vanderbecken-alban-farchi-joffrey-dumont-le-brazidec-et-yelva-roustan.-bridging-classical-data-assimilation-and-optimal-transport-2023." class="level2">
<h2 class="anchored" data-anchor-id="bocquet-marc-pierre-vanderbecken-alban-farchi-joffrey-dumont-le-brazidec-et-yelva-roustan.-bridging-classical-data-assimilation-and-optimal-transport-2023.">Bocquet, Marc, Pierre Vanderbecken, Alban Farchi, Joffrey Dumont Le Brazidec, et Yelva Roustan. Bridging classical data assimilation and optimal transport, 2023.</h2>
<p><strong>https://doi.org/10.5194/egusphere-2023-2755.</strong></p>
<p>Il rappelle tout d’abord que DA est critique pour des systèmes chaotiques pour mettre à jour les conditions initiales, estimer les paramètres physiques et statistique du modèle et permet de réanalyser l’histoire passée (smoothing). Ils présentent deux faiblesses à l’AD outre les hypothèses sur les distributions d’erreur.</p>
<ul>
<li><p><em>the double-penalty error</em>, La DA classique en sciences géophysiques présente une faiblesse majeure appelée “erreur de double pénalité”. Cela se produit lorsque les erreurs du modèle et des données observationnelles sont surpénalisées, compromettant l’équilibre nécessaire. Par exemple, un léger déplacement de polluants peut entraîner des prédictions élevées là où aucun polluant n’est observé (voir image), créant des difficultés d’évaluation du modèle. Cette erreur est répandue dans les géosciences, affectant la prévision météorologique, la chimie atmosphérique, la prévision océanique, etc. L’utilisation de l’erreur quadratique moyenne aggrave ce problème, entravant l’apprentissage efficace des modèles. C’est une composante dominante à l’erreur de représentativité. <img src="./double_penalization_error.png" class="img-fluid"></p></li>
<li><p>La mise à jour de la DA classique peut être limitée à l’espace des valeurs des champs, ce qui entraîne une analyse confinée aux limites de l’état de fond et des observations. Ceci devient une lacune majeure lorsque le désaccord entre les observations et l’état de fond résulte d’une erreur de localisation des champs ou d’une mauvaise spécification générale de ces champs. La Figure 2 illustre des expériences de DA classique avec des analyses bénéfiques et inutiles. <img src="./prior_field.png" class="img-fluid"></p></li>
</ul>
<p>On peut considérer que l’erreur provient du choix du RMSE comme mesure d’erreur, qui est une mesure localisé à une position. Une mesure plus intelligente consiste en la combinaison d’une carte de déplacement suivi de la norme classique RMSE (Hoffman et al., 1995; Keil and Craig, 2009). Des métriques basées sur des approches on pu être proposées. Une approche élégante consiste à appliquer la théorie du <em>transport optimal</em> qui est associée à la <em>distance de Wasserstein</em>. Des exemples d’utilisation d’OT peuvent être trouvé chez <em>Farchi et al.&nbsp;(2016)</em> et <em>Vanderbecken et al.&nbsp;(2023)</em>.</p>
<p>Posons quelques notations pour le transport optimal. Le problème consiste à trouver le plan au cout minimal de transporte la mesure <span class="math inline">\(\rho_0\)</span> à <span class="math inline">\(\rho_1\)</span>. Mesures donc non négative et d’intégrale à 1. Un choix d’intégral peut être aussi écrit. De plus, des généralisations pour des masses différentes ont également été faites.</p>
<p>On défini un coût défini pour tout couple de point <span class="math inline">\((x,y) \in \Omega^2\)</span> généralement fonction de la distance, on présente le coût quadratique</p>
<p><span class="math display">\[
\mathcal C_{bo}(x,y) = \norm{x-y}^2.
\]</span></p>
<p>On introduit l’ensemble des plans de transformations différentiables admissibles <span class="math inline">\(T\)</span></p>
<p><span class="math display">\[
\mathcal U_{bo} = \{T:\Omega \mapsto \Omega, \quad \rho_0 = |\partial_x T| \rho_b \circ T\},
\]</span>où <span class="math inline">\(|\partial_x T|\)</span> est le déterminant de la jacobienne de <span class="math inline">\(T\)</span> qui prend compte de la déformation de la mesure par la conservation totale de la masse.</p>
<p>On peut alors définir le carré de la distance de <em>Wasserstein</em> comme</p>
<p><span class="math display">\[
\mathcal{W}^2_{\mathcal{C_{bo}}}(\rho_0, \rho_1) = \min_{T \in \mathcal U_{bo}} \int_{\Omega} \mathcal C_{bo}(x,T(x)) \rho_0(x)dx,
\]</span> Dont le but est de minimiser le cout total de transport d’une mesure à l’autre. D’un point de vu pratique, il n’est pas possible de résoudre le problème formuler avec un plan de transport déterministe comme énoncé par Monge. Kantorovitch introduit une formulation probabiliste au <span class="math inline">\(XX^e\)</span> siècle. Le plan de transport est remplacé par une mesure de probabilité <span class="math inline">\(\pi\)</span> définie sur <span class="math inline">\(\Omega \times \Omega\)</span>.</p>
<p>L’espace des transformations admissibles devient</p>
<p><span class="math display">\[
\mathcal V_{bo} = \{\pi : \Omega \times \Omega \mapsto \mathbb R^+, quad \rho_o(x) = \int_\Omega \rho_b(y) \pi(x, y) dy, \quad \rho_b(y) = \int_\Omega \rho_o(x) \pi(x, y) dx\}.
\]</span></p>
<p>La distance de Wasserstein au carré devient alors</p>
<p><span class="math display">\[
\mathcal{W}^2_{\mathcal{C_{bo}}}(\rho_0, \rho_1) = \min_{T \in \mathcal V_{bo}} \int_{\Omega \times \Omega} \mathcal C_{bo}(x,y) \pi(x, y) dxdy.
\]</span></p>
<section id="non-local-multiscale-metrics-and-da" class="level3">
<h3 class="anchored" data-anchor-id="non-local-multiscale-metrics-and-da">Non local, multiscale metrics and DA</h3>
<p>On trouve des métriques sur l’erreur de déplacement ont pu être introduite par Ravela et al.&nbsp;(2007); Plu (2013). De même des approches multiéchelles Ying (2019); Ying et al.&nbsp;(2023). On trouve des formes proches de la distance de Wasserstein développées pour transporter la distribution du prior vers le posterior (El Moselhy and Marzouk, 2012; Oliver, 2014; Marzouk et al., 2017; Farchi and Bocquet, 2018; Tamang et al., 2020). On peut l’utiliser aussi pour ajuster les poids du filtre particulaire (Tamang et al., 2021, 2022). Elle a également été utilisée pour comparer des ensembles de forecast (Le Coz et al., 2023; Lledó et al., 110 2023), or precipitation (Duc and Sawada, 2023). Aujourd’hui on ne traite que des cas de pdf de variables aléatoires scalaire. A cause du problème du fléau de la dimension. Dans notre cas, on traite des états qui sont des champs, pas la pdf d’une seule variable. Dans les cas de champs de dimension 2 ou 3.</p>
<p>Le papier actuel se focalise plutôt en l’utilisation de la distance de Wasserstein lors de la formulation variationelle de l’analyse.</p>
<p>On part ici de la fonction de coût du 3D-Var (avec la distance Euclidenne)</p>
<p><span class="math display">\[
\mathcal J_{cl}(\bx^a) = \norm{\by^b - \bx^a}^2 + \norm{\by^o -- \bH \bx^a}^2,
\]</span></p>
<p>où <span class="math inline">\(\by^b\)</span> est la prédiction du forcast, où <span class="math inline">\(\by^o\)</span> est le vecteur des observations. En substituant la norme Euclidienne par la norme de Wasserstein on obtient la fonction de coût suivante</p>
<p><span class="math display">\[
\mathcal J_{w}(\bx^a) = \mathcal W_2^2(\bm y^b, \bx^a) +  \mathcal W_2^2(\bm y^0, \bH \bx^a).
\]</span></p>
<p>Il est nécessaire d’équilibre les deux distances. On appelle l’état d’analyse le <em>barycentre de Wasserstein</em>.</p>
<p>On remarque dans les travaux de Feyeux que cette formulation peut être inconsistente. Dans le cas où l’état est complètement observé (<span class="math inline">\(\bH\)</span> est l’identité), ’assimilation se déroule sans encombre. Un inconsistence s’observe lorsque l’état est partiellement observé. (Note: Dans notre cas, je pense que si l’observation est homogène alors tout va bien).</p>
<p><img src="image.png" class="img-fluid"></p>
<p>La principale raison à cela est de supposer que les densités d’origine et objectif ont la même masse. Ce qui s’applique pour les deux termes de calcul de distance de Wasserstein, à la fois que <span class="math inline">\(m(\bx^a) = m(\by^b)\)</span> et <span class="math inline">\(m(\bH \bx^a) = m(\by^o)\)</span>. En supposant finalement que <span class="math inline">\(m(\by^b) = m(\by^o)\)</span>, l’égalité <span class="math inline">\(m(\bx^a)=m(\bH \bx^a)\)</span> est difficilement atteignable pour <span class="math inline">\(\bx^a \in \mathbb R^{N_a}\\text{ker(\bH)}\)</span>. Il faut pour cela proposer une méthode qui puissent s’accomoder d’avoir des densités de masses différentes. Une résolution a été proposée par <em>Chizat et al.&nbsp;(2018)</em>. Ici une solution orientée DA.</p>
</section>
</section>
<section id="proposition" class="level2">
<h2 class="anchored" data-anchor-id="proposition">Proposition</h2>
<p>Hypothèses: champs physiques non-négatifs, mais pas nécessairement l’ébauche et l’observation et <span class="math inline">\(H\)</span> est supposé linéaire.</p>
<p>Sur la partie 2.5</p>
<p>Ils ont introduit l’équation (18) dans leur papier qui est une nouvelle fonction coût</p>
<p><span class="math display">\[
L_w(\bx^a) = \min_{\bx^b \in \mathcal O_{N_b}^+, \bx^o \in \mathcal O_{N_o}^+} \{\zeta_b(\by^b - \bx^b) + \zeta_o(\by^o - \bH \bx^o) +W_{\bC_{ba}}(\bx^b, \bx^a) + W_{\bC_{oa}}(\bx^o, \bx^a)\}.
\]</span></p>
<p>Cette fonction doit être minimisé en fonction de <span class="math inline">\(\bx^b, \bx^a, \bx^o\)</span>, ses trois quantités étant libres.</p>
<p>Pour cela, les auteurs présente la forme duale du problème. Cette formulation duale du problème complet est assez lourde et nécessite de déterminer un plan de transport entre les trois densités. En introduisant des multiplicateurs de Lagrange, en faisant permuter les variable à minimiser ou maximiser, on obtient finalement un problème à deux variables duales à minimiser sur un polyhèdre.</p>
<p><span class="math display">\[
\mathcal L^* = \max_{(\bf^b,\bf^o)}
\]</span></p>
<p>Pour résoudre le problème, on utilise une version simplifiée. On ne se base que sur deux transferts différents <span class="math inline">\(\bP^{ba}, \bP^{oa}\)</span>. On régularise pour obtenir</p>
<p><span class="math display">\[
\begin{aligned}
\min_{\bx^b \in \mathcal O_{N_b}^+, \bx^o \in \mathcal O_{N_o}^+, \bx^a \in \mathcal O_{N_a}^+} [\zeta_b(\by^b - \bx^b) + \zeta_o(\by^o - \bH \bx^o) + W_{\bC_{ba}}(\bx^b, \bx^a) + W_{\bC_{oa}}(\bx^o, \bx^a) \\
+ \min_{\bP^{ba} \in \mathcal{U}_ba, \bP^{oa} \in \mathcal{U}_oa} \{\varepsilon \mathcal K (\bP^{oa}|\bv^{oa}) + \varepsilon \mathcal K (\bP^{ba}|\bv^{ba}) + \Tr(\bC_{oa}^T \bP^{oa}) + \Tr(\bC_{ba}^T \bP^{ba})\}].
\end{aligned}
\]</span></p>
<p>Avec les plans respectant les contraintes de conservation.</p>
<p>On passe par la résolution du problème dual</p>
<p><span class="math display">\[
\mathcal J_{\varepsilon}^*  = \min_{\bf^b \in \mathbb{R}^{N_b}^+, \bf^o \in \mathbb{R}^{N_o}^+ \bf^a \in \mathbb{R}^{N_a}} (\bf^b, \bf^o, \bf^a),
\]</span></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>