\documentclass{article}
\usepackage{graphicx} % Pour inclure des images
\usepackage{amsmath} % Pour les environnements mathématiques
\usepackage{amssymb} % Pour les symboles mathématiques
\usepackage{bm} % Pour les symboles gras en mathématiques
\usepackage{geometry}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{hyperref}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\bv}{\bm{v}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}


\graphicspath{ {images} }

\bibliographystyle{plain}
\begin{document}

\title{Alignement des champs de vorticité}
\author{Marius Duvillard}
\date{\today}
\maketitle


\section{Définition du problème}
On suppose que les champs de vorticité ont été mal aligné. Pour corriger cette erreur, on souhaite appliquer une correction qui respecte les contraintes d'un écoulement incompressible. Pour cela, on introduit un transformation $\Phi$ qui doit corriger l'ébauche.
On réécrit la loi de Bayes avec cette information

\begin{equation*}
    p(\omega,\Phi \mid y) \propto p(y \mid \omega, \Phi) p(\omega \mid \Phi) p(\Phi)
\end{equation*}

\begin{equation*}
    p(\omega,u \mid y) \propto p(y \mid \omega,u) p(\omega \mid u) p(u)
\end{equation*}

Pour les deux premiers termes on retrouve facilement la vraissemblance conditionnée par l'ébauche déformée c'est à dire $\Phi(\omega)$ qui est appliqué sur les coordonnées lagrangienne du champ.
Le prior est également défini sur le champ déformé. Enfin il faut définir un prior pour $\Phi$. Ce terme est assez arbitraire. On veut simplement qu'il vérifie la condition d'un écoulement incompressible.

Le champ de vorticité est porté par une discrétisation particulaire $\mathcal P = \{(x_p, \Gamma_p)\}$ tel que pour tout $x \in \Omega$

\begin{equation*}
    \omega(x) = \sum_{p = 1}^{n_p} \Gamma_p \phi_\varepsilon(x - x_p)
\end{equation*}

La transformation $\Phi$ est une transformation qui s'applique sur la position des particules de la discrétisation, tel que $\omega_\Phi$ le nouveau champ de vorticité est

\begin{equation*}
    \omega_\Phi(x) = \sum_{p = 1}^{n_p} \Gamma_p \phi_\varepsilon(x - \Phi(x_p)).
\end{equation*}

A partir de ces définitions, la distribution a posteriori peut être réécrite:

\begin{itemize}
    \item La vraissemblance devient alors
          \begin{equation*}
              p(y \mid \omega, \Phi) \propto \exp\left(-\frac{1}{2}\norm{y - h(\omega_\Phi)}^2_{R^{-1}}\right),
          \end{equation*}où $R$ la matrice de covariance des observations ;
    \item Le prior sur les amplitudes d'ébauche devient
          \begin{equation*}
              p(\omega \mid \Phi) \propto \frac{1}{\sqrt{|P(\Phi)|}} \exp\left(-\frac{1}{2} \norm{\omega_{\Phi} - \omega^f}^2_{P(\Phi)^{-1}}\right),
          \end{equation*}où $P(\Phi)$ la matrice (ou fonction) de covariance de l'état après transformation.
    \item finalement le prior sur le déplacement est défini
          \begin{equation*}
              p(\Phi) \propto \exp\left(-L(\Phi)\right),
          \end{equation*}où $L$ est une fonction à définir.
\end{itemize}

Nous obtenons une fonctionnelle à minimiser à partir de la log vraissemblance tel que

\begin{equation*}
    \mathcal L(\omega, \Phi) = \frac{1}{2}\norm{y - h(\omega_\Phi)}^2_{R^{-1}} + \frac{1}{2} \norm{\omega_{\Phi} - \omega^f}^2_{P(\Phi)^{-1}} + L(\Phi) - \frac{1}{2} \ln(|P(\Phi)|).
\end{equation*}

\begin{equation*}
    \mathcal L(\omega, u) = \frac{1}{2}\norm{y - h(\omega_{\Phi(u)})}^2_{R^{-1}} + \frac{1}{2} \norm{\omega_{\Phi(u)} - \omega^f}^2_{P_{\Phi(u)}^{-1}} - \frac{1}{2} \ln(|P(\Phi(u))|) + \frac\lambda 2 \norm{u}^2_{P_u^{-1}} .
\end{equation*}

En plus de la formule variationnelle habituelle, on observe également le terme lié à la normalisation sur le prior des amplitudes.

Comment dans Ravela 2007, plusieurs méthodes de résolution peuvent être proposées. Une première proposition est de proposer une formulation itérative. L'objectif est de fixer $P$ pour la mise à jour, et d'utiliser ensuite les membres pour mettre à jour cette matrice de covariance. $P^-$ est initialisée à 0 et on défini une nouvelle fonctionnelle

\begin{equation*}
    \mathcal L(\omega, \Phi \mid \Phi^-) = \frac{1}{2}\norm{y - h(\omega_\Phi)}^2_{R^{-1}} + \frac{1}{2} \norm{\omega_{\Phi} - \omega^f}^2_{P(\Phi^-)^{-1}} + L(\Phi) - \frac{1}{2} \ln(|P(\Phi^-)|).
\end{equation*}

Celle-ci peut-être minimisée pour $(\omega, \Phi)$ simultanément. Nous proposons de séparer l'étape d'alignement et de correction des intensitées. Pour cela, nous faisons une approximation en utilisant les équations d'Euler-Lagrange.

On peut en déduire deux fonctions coût à minimiser

\begin{align*}
    \mathcal L(\Phi)   & =  \frac{1}{2}\norm{y - h(\omega_\Phi)}^2_{R^{-1}} + L(\Phi)                                                      \\
    \mathcal L(\omega) & =  \frac{1}{2}\norm{y - h(\omega_\Phi)}^2_{R^{-1}} + \frac{1}{2} \norm{\omega_{\Phi} - \omega^f}^2_{P(\Phi)^{-1}}
\end{align*}

\section{Correction dans le span des champs de vitesse des membres}

On cherche une transformation définie par l'intégration de la position d'un jeu de particule $\mathcal P = \{(x_p, \Gamma_p)\}$ par un champs de vitesse $u$ tel que

\begin{eqnarray*}
    x_p(t;u) &=& x_p^0 + \int_{0}^{t} u(x_p(t')) \mathrm dt' \\
    \Phi(x_p^0, u) &=& x_p(t=1; u).
\end{eqnarray*}

\begin{eqnarray*}
    \Phi(x_p, u)  &=& x_p + \int_{0}^{1} u(x_p(t)) \mathrm dt
\end{eqnarray*}

On souhaite identifier ce champ de vitesse tel que

\begin{equation*}
    u = \argmin_{u \in \mathcal{V}} \norm{u^{obs} - h_u(\{(x_p, \Gamma_p)\}; x_{obs}, u)}^2_{R^{-1}}.
\end{equation*}où $u^{obs}$ sont les vitesse observées en $x_{obs}$, $h_u$ l'opérateur d'observation après application du champ de vitesse $u$ pour déplacer les particules.

Le champ $u$ est défini dans un espace vectoriel $\mathcal{V}$ dans lequel il admet une décomposition.

Dans un premier temps on choisi $\mathcal{V} = \text{Span}(u_m)$ où $u_m$ est le champ de vitesse du $m$-ème membre.

Ce choix est cohérent car par CL, il permet de définir une transformation à divergence nulle.
De plus, il est cohérent avec la philosophie du filtre de Kalman d'utiliser la distribution des membres.

Ainsi le champ $u$ se réécrit comme $u = \sum_m a_m u_m$.

On peut réécrire la fonction objectif en fonction du vecteur $a \in \mathbb{R}^N$

\begin{equation*}
    \mathcal L_a =  \norm{u^{obs} - h_a(\{(x_p, \Gamma_p)\}; x_{obs}, a)}^2_{R^{-1}}.
\end{equation*}

Il convient de définir l'opérateur $h$ comme l'observation du champ de vitesse aux coordonnées $x_{obs}$ après déplacement des particules selon $u$

\begin{equation*}
    h_a(\{(x_p, \Gamma_p)\}; x_{obs}, a) = h(\{(\tilde x_p, \Gamma_p)\}; x_{obs}) = U_{obs}(\tilde x_p, \Gamma_p).
\end{equation*}

Du fait de la non-linéarité du problème (non linéarité de $x(t;a)$ par rapport à $a$), le problème n'est pas convexe. On se propose de résoudre le problème à l'aide d'un algoritme de minimisation NL. Pour cela on souhaite évaluer le gradient de $\mathcal L_a$.

Dans un premier temps, ce vecteur est évalué par approximation de la dérivée directionnelle

\begin{equation*}
    \frac{\partial \mathcal L_a}{\partial a_i}(a) = D_{u_i} \mathcal L_a(a) \approx \frac{\mathcal L_a(a + \delta a_i e_i) - \mathcal L_a(a)}{\delta a_i}
\end{equation*}

Connaissant $\mathcal L_a$ et son gradient, on peut appliquer des algorithmes de minimisation NL.

\section{Calcul de la dérivée}

Le calcul de la dérivée par différence finie nécessite de réaliser $M$ forward supplémentaire, ce qui peut être couteux. Une alternative consiste à déterminer une faiseau principal et de déterminer $M$ perturbation autour de cette trajectoire. Supposons que nous souhaitions calculer $\nabla_a h$. Pour cela nous perturbons le champ d'alignement $v(a)$ selon les direction $e_i$ tel que $a' = a + \varepsilon e_i$. Cette perturbation va entraîner une déviation autour de la trajectoire en $a$ que l'on note $x_a$ tel que $x_{a'}(t) = x_a(t) + \varepsilon x_1(t) + \varepsilon^2 x_2(t), \dots$.
La dérivée particulaire donne

\begin{equation*}
    \frac{d}{dt}(x_a + \varepsilon x_1 + \varepsilon^2 x_2, \dots) = \sum_j a_j u_j(x_a + \varepsilon x_1 + \varepsilon^2 x_2, \dots) + \varepsilon a_i u_i (x_a + \varepsilon x_1 + \varepsilon^2 x_2, \dots)
\end{equation*}

Par développement en série de Taylor on obtient pour les différents champs de vitesse $u_j$
\begin{equation*}
    u_j(x_a + \varepsilon x_1 + \varepsilon^2 x_2, \dots) = u_j(x_a) + (\varepsilon x_1 + \varepsilon^2 x_2, \dots) \nabla_x u_j (x_a) + o(\varepsilon)
\end{equation*}

En substituant dans la première expression, on obtient les deux premiers ordres du développement
\begin{eqnarray*}
    \frac{dx_a}{dt} &=&    \sum_j a_j u_j(x_a) \\
    \frac{dx_1}{dt} &=&   \sum_j a_j x_1 \nabla_x u_j(x_a) + a_i u_i(x_a).
\end{eqnarray*}

Ainsi, la position finale des particules $x_{a'}(t = 1) = x_{a}(t = 1) + \varepsilon x_1(t=1)$.

Pour ce faire, on pourra résoudre le problème joint

\begin{equation*}
    \begin{cases}
        \frac{dx_a}{dt}      & =  \sum_j a_j u_j(x_a),                                     \\
        x_a(t=0)             & =  x_a^0,                                                   \\
        i = 1, \dots, M:                                                                   \\
        \frac{d\hat x_i}{dt} & =  \hat x_i (\sum_j a_j  \nabla_x u_j(x_a)) + a_i u_i(x_a), \\
        \hat x_i(t=0)        & =  0.
    \end{cases}
\end{equation*}

\section{Ajout du prior}
On souhaite tenir compte de notre prior dans la fonction coût. En effet, la fonction de coût de la posterior est la suivante

\begin{equation*}
    \mathcal L_a =  \frac12 \norm{u^{obs} - h_a(\{(x_p, \Gamma_p)\}; x_{obs}, a)}^2_{R^{-1}} +  \frac{\lambda}{2} \norm{u}^2_{P^+}.
\end{equation*}

\begin{align*}
    \mathcal L_u(u)           & =  \frac12 \norm{u^{obs} - h(\omega_{\Phi(u)})}^2_{R^{-1}} + \frac{\lambda}{2} \norm{u}^2_{P_u^{-1}}             \\
    \mathcal L_\omega(\omega) & =  \frac12 \norm{u^{obs} - h(\omega)}^2_{R^{-1}} + \frac{1}{2} \norm{\omega - \omega_{\Phi}^f}^2_{P_{\Phi}^{-1}}
\end{align*}

\begin{equation*}
    \mathcal L_a(a)            =  \frac12 \norm{u^{obs} - h(\omega_{a})}^2_{R^{-1}} + \frac{\lambda}{2} \norm{a}^2_2
\end{equation*}

On a besoin d'introduire un paramètre $\lambda$ car l'intégration est réaliser sur un interval de temps fictif.

Avec la norme sur $u$ qui est

\begin{eqnarray*}
    \norm{u}^2_{P^+} = \int_{\omega^2} u(x) P^+(x, x') u(x') \mathrm{d}x\mathrm{d}x' \\
\end{eqnarray*}



% Avec $P$ la pseudo-inverse de $P$. Or $P$ est défini à partir de l'ensemble même

% \begin{equation*}
%     P(x, x') = \sum_i^M  u_i(x) u_i(x')
% \end{equation*}

% Or par décomposition de la solution en $u = \sum_i a_i u_i$, on obtient

% \begin{eqnarray*}
%     \norm{u}^2_{P^+} &=& \sum_i \sum_j a_i a_j \int_{\omega^2} u^i(x) P^+(x, x') u(x') \mathrm{d}x\mathrm{d}x', \\
%     &=& \sum_j a_i a_j \int_{\omega^2} \delta{x'} \delta{x}\mathrm{d}x\mathrm{d}x', \\
%     &=& \sum_i \sum_j a_i a_j \propto \norm{a}_2^2
% \end{eqnarray*}

On peut également écrire la norme différemment. On constate que la fonction coût est infinie si $u \in \text{Ker} (P)$. Ainsi, on peut écrire une décomposition de $u$ comme

\begin{equation*}
    u = P v
\end{equation*} où $v \in L(\Omega)$. $P$ n'étant pas de rang plein, il existe une infinité de vecteur $a$ qui vérifie cette propriété. Nous choisissons de les décomposer comme $v = v^* \oplus v^\perp$ avec $v^\perp \in \text{Ker}(P)$. On défini alors le pseudo inverse $P^+$ tel que

\begin{equation*}
    P^+ u = v^*
\end{equation*}

Ainsi on peut la norme en fonction de $v^*$

\begin{equation*}
    \norm{u}^2_{P^+} = \langle u, P^+ u \rangle = \langle v^*, P v^* \rangle = \langle v, P v \rangle
\end{equation*}

Or, $P v$ peut être défini dans une décomposition sur la famille des membres en effet

\begin{equation*}
    P = \frac1N \sum_{i=1}^N u_i \otimes u_i
\end{equation*}

Ce qui implique que

\begin{equation*}
    P v = \frac1N \sum_{i=1}^N \langle u_i, v \rangle u_i
\end{equation*}

On note le vecteur $a \in \mathbb{R}^N$ une décomposition de $Pv$ dans la famille des membres qui vérifie cette projection. On obtient finalement une nouvelle expression pour la norme

\begin{equation}
    \norm{u}^2_{P^+} = \langle v, P v \rangle = \frac1N \sum_{i=1}^N a_i \langle u_i, v\rangle = \frac1N \sum_{i=1}^N a_i^2 = \frac1N \norm{a}^2_2
\end{equation}


\section{Méthode de gradient à l'origine}

On part de la fonction coût suivante
\begin{equation*}
    \mathcal L_a =  \frac12 \norm{u^{obs} - h_a(\{(x_p, \Gamma_p)\}; x_{obs}, a)}^2_{R^{-1}}
\end{equation*}

Mais cette fois le champ d'alignement est paramétré différemment avec $a$.
Ici, on cherche à déterminer la meilleure direction de champ de vitesse pour minimiser la fonction coût en appliquant une vitesse telle que

\begin{equation*}
    \frac{dx}{dt} = \sum_i a_i(t) u_i(x).
\end{equation*}

On cherche à faire diminuer au cours du temps $t$ la fonction coût $\mathcal L_a$ ce qui revient à minimiser

La fonction de coût est donc paramétrée par deux variables $a$ et $t$

\begin{equation*}
    \mathcal L_a(a;t) =  \frac12 \norm{u^{obs} - h(x(t,a(t)); x_{obs})}^2_{R^{-1}}
\end{equation*}

On souhaite appliquer la vitesse qui va maximiser la variation négative de $L_a$ à $t=t_0$.

Cela revient à résoudre pour $a$

\begin{equation*}
    \min_{a\in \mathbb{R}^M,~\norm{a}^2 = 1} \frac{\partial L_a}{\partial t}(a;t) =  \frac12 \norm{u^{obs} - h(x(t,a(t)); x_{obs})}^2_{R^{-1}}
\end{equation*}

Cela est vrai pour deux le deux points $a_1 = \nabla_x h U / \norm{\nabla_x h U }$ et $a_2 = - \nabla_x h U / \norm{\nabla_x h U }$

\begin{equation*}
    \min_{a \in \mathbb{R}^M,~\norm{a}^2 = 1} \frac{d \mathcal L_a}{dt} = \sum_i (\nabla_x \mathcal L_a \cdot u_i ) a_i
\end{equation*}

A partir des nouvelles valeurs de $a$ on applique le champ de vitesse sur un petit incrément $x^{n+1} = x^n + \left(\sum_i a_i u_i\right) dt$.

On procède de même au pas de temps suivant.

On a donc un problème linéaire avec contrainte quadratique (LPQC) à résoudre.

Le calcul du terme $\nabla_x \mathcal L_a \cdot u_i$ est en fait la dérivée directionnelle $D_{u_i} \mathcal L_a(a)$, où ici $a_i$ sont les composantes de la dérivée de vitesse à appliqué à l'instant $t$.














% \section{Correction dans le span des champs de vitesse des membres 2}

% Après simplification, on voudrait arriver à la forme suivante du problème: Définir la transformation comme l'intégration d'un champ de vitesse combinaison des champs de vitesse des membres $v_i$ à l'instant $t$.

% Pour cela, on cherche un champ de vitesse $v$ qui aura comme distribution a priori $\mathcal N (v_0,  P_v)$ avec $\bv_0 = 0$ et $P_v = \frac{1}{N - 1}\sum (v_i - \bar v) (v_i - \bar v)^T$

% Le problème à minimiser est alors pour le membre $i$

% \begin{equation*}
%     \mathcal L(v) = \norm{d_v - h_v(v; \omega_i)}^2_{R^{-1}} + \norm{v - \bar v}^2_{P_{v}^{-1}}
% \end{equation*}

% En fait on peut chercher à réécrire le problème dans le Span de l'ensemble et ainsi trouver la combinaison linéaire en $v_i$.


% On note $V \in \mathbb R^{d \times N}$ l'ensemble des champs de vitesse où $d$ est la dimension de $v$ et $N$ la taille de l'ensemble. On cherche alors $b \in \mathcal R^{N}$ tel que

% \begin{equation*}
%     v = v_i + Vb
% \end{equation*}

% Tel que $\Phi$ devient

% \begin{equation*}
%     \Phi(x, y) = (x, y) + dt v_i(x, y) + dt \sum_j b_j v_j(x, y)
% \end{equation*}

% On a bien $\Phi$ qui est linéaire avec $b$

% \begin{equation*}
%     \norm{v - \bar v}^2_{P^{-1}} = \norm{b}^2_2
% \end{equation*}

% et d'autre part on doit linéarise $h$ par rapport à $v$.

% Pour cela,  étudions $h$. C'est la mesure de la vitesse après application intégration de l'advection de $\omega_i$ c'est à dire faire

% \begin{equation*}
%     h_v(v; \omega_i) = h_\omega(\Phi(\omega_i)) = h_{\omega}(\omega((x, y)+ dt v_i(x, y) + dt \sum_j b_j v_j(x, y)))
% \end{equation*}

% La difficulté maintenant est de déduire du déplacement de $\omega$, la variation de vitesse

% Pour cela on doit étudier la linéarisation de l'équation de la fonction de courant.

% On note $\hat \omega$ la nouvelle vorticité

% \begin{eqnarray*}
%     \Delta \psi  &=& \hat \omega \\
%     &=& \omega((x, y)+ dt v_i(x, y) + dt \sum_j b_j v_j(x, y)) \\
%     &=&
% \end{eqnarray*}


% \begin{eqnarray*}
%     h(v; \omega_i) = v
% \end{eqnarray*}


\end{document}