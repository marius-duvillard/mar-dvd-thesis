@article{greenwade93,
  author  = {Greenwade, George D.},
  title   = {The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})},
  year    = {1993},
  journal = {TUGBoat},
  volume  = {14},
  number  = {3},
  pages   = {342--351}
}
    
@article{degroot1962,
  author  = {DeGroot, M. H.},
  title   = {Uncertainty, Information, and Sequential Experiments},
  journal = {The Annals of Mathematical Statistics},
  year    = {1962},
  volume  = {33},
  pages   = {404--419},
  number  = {2}
}

@inproceedings{diaconis1988,
  author    = {Diaconis, P.},
  title     = {{B}ayesian numerical analysis},
  booktitle = {Statistical Decision Theory and Related Topics IV},
  year      = {1988},
  pages     = {163--175}
}
  
@article{cowie2022,
  title   = {The Sixth Mass Extinction: fact, fiction or speculation?},
  author  = {Cowie, R.~H. and Bouchet, P. and Fontaine, B.},
  journal = {Biological Reviews},
  year    = {2022},
  volumne = {97},
  number  = {2},
  pages   = {640--663}
}

@book{evensen_data_2022,
  series     = {Springer {Textbooks} in {Earth} {Sciences}, {Geography} and {Environment}},
  title      = {Data {Assimilation} {Fundamentals}: {A} {Unified} {Formulation} of the {State} and {Parameter} {Estimation} {Problem}},
  isbn       = {978-3-030-96708-6 978-3-030-96709-3},
  shorttitle = {Data {Assimilation} {Fundamentals}},
  url        = {https://link.springer.com/10.1007/978-3-030-96709-3},
  language   = {en},
  urldate    = {2022-11-16},
  publisher  = {Springer International Publishing},
  author     = {Evensen, Geir and Vossepoel, Femke C. and van Leeuwen, Peter Jan},
  year       = {2022},
  doi        = {10.1007/978-3-030-96709-3},
  keywords   = {4DVar, Data Assimilation, Ensemble Kalman Filter, Ensemble Methods, Open Access, Parameter Estimation, Particle Filter, Particle Flow, Representer Method}
}

@book{asch_data_2016,
  address    = {Philadelphia},
  series     = {Fundamentals of algorithms},
  title      = {Data assimilation: methods, algorithms, and applications},
  isbn       = {978-1-61197-454-6},
  shorttitle = {Data assimilation},
  language   = {en},
  number     = {11},
  publisher  = {Society for Industrial and Applied Mathematics},
  author     = {Asch, Mark and Bocquet, Marc and Nodet, Maëlle},
  year       = {2016},
  keywords   = {Algorithms, Inverse problems (Differential equations), Numerical analysis}
}


@article{evensen_sequential_1994,
  title    = {Sequential data assimilation with a nonlinear quasi-geostrophic model using {Monte} {Carlo} methods to forecast error statistics},
  volume   = {99},
  issn     = {2156-2202},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1029/94JC00572},
  doi      = {10.1029/94JC00572},
  abstract = {A new sequential data assimilation method is discussed. It is based on forecasting the error statistics using Monte Carlo methods, a better alternative than solving the traditional and computationally extremely demanding approximate error covariance equation used in the extended Kalman filter. The unbounded error growth found in the extended Kalman filter, which is caused by an overly simplified closure in the error covariance equation, is completely eliminated. Open boundaries can be handled as long as the ocean model is well posed. Well-known numerical instabilities associated with the error covariance equation are avoided because storage and evolution of the error covariance matrix itself are not needed. The results are also better than what is provided by the extended Kalman filter since there is no closure problem and the quality of the forecast error statistics therefore improves. The method should be feasible also for more sophisticated primitive equation models. The computational load for reasonable accuracy is only a fraction of what is required for the extended Kalman filter and is given by the storage of, say, 100 model states for an ensemble size of 100 and thus CPU requirements of the order of the cost of 100 model integrations. The proposed method can therefore be used with realistic nonlinear ocean models on large domains on existing computers, and it is also well suited for parallel computers and clusters of workstations where each processor integrates a few members of the ensemble.},
  language = {en},
  number   = {C5},
  urldate  = {2022-10-14},
  journal  = {Journal of Geophysical Research: Oceans},
  author   = {Evensen, Geir},
  year     = {1994},
  pages    = {10143--10162}
}


@article{zhang_smoothed_2022,
  title      = {Smoothed particle hydrodynamics: {Methodology} development and recent achievement},
  volume     = {34},
  issn       = {1878-0342},
  shorttitle = {Smoothed particle hydrodynamics},
  url        = {https://doi.org/10.1007/s42241-022-0052-1},
  doi        = {10.1007/s42241-022-0052-1},
  abstract   = {Since its inception, the full Lagrangian meshless smoothed particle hydrodynamics (SPH) has experienced a tremendous enhancement in methodology and impacted a range of multi-physics applications in science and engineering. This review presents a concise survey on latest developments and achievements of the SPH method, including: (1) Brief review of theory and fundamental with kernel corrections, (2) The Riemann-based SPH method with dissipation limiting and high-order data reconstruction by using MUSCL, WENO and MOOD schemes, (3) Particle neighbor searching with particle sorting and efficient dual-criteria time stepping schemes, (4) Total Lagrangian formulation with stablized, dynamics relaxation and hourglass control schemes, (5) Fluid-structure interaction scheme with interface treatments and multi-resolution discretizations, (6) Novel applications of particle relaxation in SPH methodology for mesh and particle generations. Last but not least, benchmark tests for validating computational accuracy, convergence, robustness and efficiency are also supplied accordingly.},
  language   = {en},
  number     = {5},
  urldate    = {2022-12-21},
  journal    = {Journal of Hydrodynamics},
  author     = {Zhang, Chi and Zhu, Yu-jie and Wu, Dong and Adams, Nikolaus A. and Hu, Xiangyu},
  month      = oct,
  year       = {2022},
  keywords   = {fluid-structure interaction, mesh and particle generation, Riemann-based SPH, Smoothed particle hydrodynamics (SPH), update and total Lagrangian formulations},
  pages      = {767--805},
  file       = {Full Text PDF:\\\\robion1\\homes\\home-global\\Zotero\\storage\\2GRX6ML8\\Zhang et al. - 2022 - Smoothed particle hydrodynamics Methodology devel.pdf:application/pdf}
}

@incollection{de_vaucorbeil_material_2020,
  title      = {Material point method after 25 years: {Theory}, implementation, and applications},
  volume     = {53},
  isbn       = {978-0-12-820989-9},
  shorttitle = {Material point method after 25 years},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S0065215619300146},
  abstract   = {It has been 25 years since Sulsky and her co-workers developed the ﬁrst version of the material point method (MPM): a quasi particle method to solve continuum mechanics problems. In the MPM, the continua are discretized by Lagrangian particles moving over a ﬁxed Eulerian background grid. As a result, large deformation and contact can be treated effortlessly. Since then, many improved instances of the MPM have been developed and the MPM has found applications in many ﬁelds from geoengineering to movie industry. As the MPM has now been matured and a large body of literature on it exists, it is a good time to ponder and reﬂect on the developments of the method to date. To this end, this manuscript provides a concise introduction to the MPM, covering theory, implementation and applications. All the algorithms required to have a working MPM implementation for the simulations of solids, ﬂuids and their interactions are provided. We have coded these algorithms in in-house open source programs and used them to study the performance of different MPM variants for large deformation solid mechanics problems. These problems exhibit large plastic deformation, fractures and contacts. Convergence of different MPMs (CPDI, GIMP, B-splines, Total Lagrangian MPM, improved MPMs) are studied. Furthermore, MPM formulations for ﬂuids/gases and heat conduction are also covered. Potential areas for improvement on the method have been identiﬁed. The paper is the ﬁrst review of the MPM and presents a state-of-the-art of the current MPM literature covering 339 references.},
  language   = {en},
  urldate    = {2022-01-14},
  booktitle  = {Advances in {Applied} {Mechanics}},
  publisher  = {Elsevier},
  author     = {de Vaucorbeil, Alban and Nguyen, Vinh Phu and Sinaie, Sina and Wu, Jian Ying},
  year       = {2020},
  doi        = {10.1016/bs.aams.2019.11.001},
  pages      = {185--398}
}




@article{sulsky_particle_1994,
  title    = {A particle method for history-dependent materials},
  abstract = {A broad class of engineering problems including penetration, tmpact and large rotations of solid bodies causes severe numerical problems. For these problems, the constitutive equations are history dependent so material points must be followed; this is difficult to implement in a Eulerian scheme. On the other hand, purely Lagrangian methods typically result in severe mesh distortion and the consequence is ill conditioning of the element stiffness matrix leading to mesh lookup or entanglement. Remeshing prevents the lookup and tangling but then interpolation must be performed for history dependent variables, a process which can introduce errors. Proposed here is an extension of the particle-in-cell method in which particles are interpreted to be material points that are followed through the complete loading process. A fixed Eulerian grid provides the means for determining a spatial gradient. Because the grid can also be interpreted as an updated Lagrungian frame, the usual convection term in the acceleration associated with Eulerian formulations does not appear. With the use of maps between material points and the grid, the advantages of both Eulerian and Lagrangian schemes are utilized so that mesh tangling is avoided while material variables are tracked through the complete deformation history. Example solutions in two dimensions are given to illustrate the robustness of the proposed convection algorithm and to show that typical elastic behavior can be reproduced. Also, it is shown that impact with no slip is handled without any spe{\textasciitilde}cialalgorithm for bodies governed by elasticity and strain hardening plasticity.},
  language = {en},
  author   = {Sulsky, D and Chenb, Z and Schreyer, H L},
  year     = {1994},
  pages    = {18},
  journal  = {Computer methods in applied mechanics and engineering},
  file     = {Sulskya et al. - A particle method for history-dependent materials.pdf:\\\\robion1\\homes\\home-global\\Zotero\\storage\\EXUMXXH8\\Sulskya et al. - A particle method for history-dependent materials.pdf:application/pdf}
}


@article{janjic_conservation_2014,
  title    = {Conservation of {Mass} and {Preservation} of {Positivity} with {Ensemble}-{Type} {Kalman} {Filter} {Algorithms}},
  volume   = {142},
  issn     = {0027-0644, 1520-0493},
  url      = {http://journals.ametsoc.org/doi/10.1175/MWR-D-13-00056.1},
  doi      = {10.1175/MWR-D-13-00056.1},
  abstract = {This paper considers the incorporation of constraints to enforce physically based conservation laws in the ensemble Kalman ﬁlter. In particular, constraints are used to ensure that the ensemble members and the ensemble mean conserve mass and remain nonnegative through measurement updates. In certain situations ﬁltering algorithms such as the ensemble Kalman ﬁlter (EnKF) and ensemble transform Kalman ﬁlter (ETKF) yield updated ensembles that conserve mass but are negative, even though the actual states must be nonnegative. In such situations if negative values are set to zero, or a log transform is introduced, the total mass will not be conserved. In this study, mass and positivity are both preserved by formulating the ﬁlter update as a set of quadratic programming problems that incorporate nonnegativity constraints. Simple numerical experiments indicate that this approach can have a signiﬁcant positive impact on the posterior ensemble distribution, giving results that are more physically plausible both for individual ensemble members and for the ensemble mean. In two examples, an update that includes a nonnegativity constraint is able to properly describe the transport of a sharp feature (e.g., a triangle or cone). A number of implementation questions still need to be addressed, particularly the need to develop a computationally efﬁcient quadratic programming update for large ensemble.},
  language = {en},
  number   = {2},
  urldate  = {2022-06-07},
  journal  = {Monthly Weather Review},
  author   = {Janjić, Tijana and McLaughlin, Dennis and Cohn, Stephen E. and Verlaan, Martin},
  month    = feb,
  year     = {2014},
  pages    = {755--773},
  file     = {Janjić et al. - 2014 - Conservation of Mass and Preservation of Positivit.pdf:\\\\robion1\\homes\\home-global\\Zotero\\storage\\AIANCH7I\\Janjić et al. - 2014 - Conservation of Mass and Preservation of Positivit.pdf:application/pdf}
}


@article{albers_ensemble_2019,
  title    = {Ensemble {Kalman} methods with constraints},
  volume   = {35},
  issn     = {0266-5611, 1361-6420},
  url      = {https://iopscience.iop.org/article/10.1088/1361-6420/ab1c09},
  doi      = {10.1088/1361-6420/ab1c09},
  abstract = {Ensemble Kalman methods constitute an increasingly important tool in both state and parameter estimation problems. Their popularity stems from the derivative-free nature of the methodology which may be readily applied when computer code is available for the underlying state-space dynamics (for state estimation) or for the parameter-to-observable map (for parameter estimation). There are many applications in which it is desirable to enforce prior information in the form of equality or inequality constraints on the state or parameter. This paper establishes a general framework for doing so, describing a widely applicable methodology, a theory which justifies the methodology, and a set of numerical experiments exemplifying it.},
  language = {en},
  number   = {9},
  urldate  = {2022-10-04},
  journal  = {Inverse Problems},
  author   = {Albers, David J and Blancquart, Paul-Adrien and Levine, Matthew E and Esmaeilzadeh Seylabi, Elnaz and Stuart, Andrew},
  month    = sep,
  year     = {2019},
  pages    = {095007},
  file     = {Albers et al. - 2019 - Ensemble Kalman methods with constraints.pdf:\\\\robion1\\homes\\home-global\\Zotero\\storage\\JJWIQBI6\\Albers et al. - 2019 - Ensemble Kalman methods with constraints.pdf:application/pdf}
}

@article{plu_variational_2013,
  title    = {A variational formulation for translation and assimilation of coherent structures},
  volume   = {20},
  issn     = {1023-5809},
  url      = {https://npg.copernicus.org/articles/20/793/2013/npg-20-793-2013.html},
  doi      = {10.5194/npg-20-793-2013},
  abstract = {The assimilation of observations from teledetected images in geophysical models requires one to develop algorithms that would account for the existence of coherent structures. In the context of variational data assimilation, a method is proposed to allow the background to be translated so as to fit structure positions deduced from images. Translation occurs as a first step before assimilating all the observations using a classical assimilation procedure with specific covariances for the translated background. A simple validation is proposed using a dynamical system based on the one-dimensional complex Ginzburg–Landau equation in a regime prone to phase and amplitude errors. Assimilation of observations after background translation leads to better scores and a better representation of extremas than the method without translation.},
  language = {English},
  number   = {5},
  urldate  = {2024-01-03},
  journal  = {Nonlinear Processes in Geophysics},
  author   = {Plu, M.},
  month    = oct,
  year     = {2013},
  note     = {Publisher: Copernicus GmbH},
  pages    = {793--801},
  file     = {Full Text PDF:C\:\\Users\\md266594\\Zotero\\storage\\4466GTSH\\Plu - 2013 - A variational formulation for translation and assi.pdf:application/pdf}
}

@article{ravela_data_2007,
  title    = {Data assimilation by field alignment},
  volume   = {230},
  issn     = {01672789},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0167278906003551},
  doi      = {10.1016/j.physd.2006.09.035},
  abstract = {Classical formulations of data assimilation, whether sequential, ensemble-based or variational, are amplitude adjustment methods. Such approaches can perform poorly when forecast locations of weather systems are displaced from their observations. Compensating position errors by adjusting amplitudes can produce unacceptably “distorted” states, adversely affecting analysis, veriﬁcation and subsequent forecasts.},
  language = {en},
  number   = {1-2},
  urldate  = {2022-09-22},
  journal  = {Physica D: Nonlinear Phenomena},
  author   = {Ravela, Sai and Emanuel, Kerry and McLaughlin, Dennis},
  month    = jun,
  year     = {2007},
  pages    = {127--145},
  file     = {Ravela et al. - 2007 - Data assimilation by field alignment.pdf:C\:\\Users\\md266594\\Zotero\\storage\\XSYM6T3S\\Ravela et al. - 2007 - Data assimilation by field alignment.pdf:application/pdf}
}


@book{bocquet_bridging_2023,
  title    = {Bridging classical data assimilation and optimal transport},
  abstract = {Because optimal transport acts as displacement interpolation in physical space rather than as interpolation in value space, it can potentially avoid double penalty errors. As such it provides a very attractive metric for non-negative physical fields comparison – the Wasserstein distance – which could further be used in data assimilation for the geosciences. The algorithmic and numerical implementations of such distance are however not straightforward. Moreover, its theoretical formulation within typical data assimilation problems face conceptual challenges, resulting in scarce contributions on the topic in the literature. We formulate the problem in a way that offers a unified view on both classical data assimilation and optimal transport. The resulting OTDA framework accounts for both the classical source of prior errors, background and observation, together with a Wasserstein barycentre in between states that stand for these background and observation. We show that the hybrid OTDA analysis can be decomposed as a simpler OTDA problem involving a single Wasserstein distance, followed by a Wasserstein barycentre problem which ignores the prior errors and can be seen as a McCann interpolant. We also propose a less enlightening but straightforward solution to the full OTDA problem, which includes the derivation of its analysis error covariance matrix. Thanks to these theoretical developments, we are able to extend the classical 3D-Var/BLUE paradigm at the core of most classical data assimilation schemes. The resulting formalism is very flexible and can account for sparse, noisy observations and non-Gaussian error statistics. It is illustrated by simple one– and two–dimensional examples that show the richness of the new types of analysis offered by this unification.},
  author   = {Bocquet, Marc and Vanderbecken, Pierre and Farchi, Alban and Dumont Le Brazidec, Joffrey and Roustan, Yelva},
  month    = dec,
  year     = {2023},
  doi      = {10.5194/egusphere-2023-2755},
  file     = {Full Text PDF:C\:\\Users\\md266594\\Zotero\\storage\\7AKUVBGU\\Bocquet et al. - 2023 - Bridging classical data assimilation and optimal t.pdf:application/pdf}
}

@article{rosenthal_displacement_2017,
  title    = {Displacement data assimilation},
  volume   = {330},
  issn     = {0021-9991},
  url      = {https://www.sciencedirect.com/science/article/pii/S002199911630523X},
  doi      = {10.1016/j.jcp.2016.10.025},
  abstract = {We show that modifying a Bayesian data assimilation scheme by incorporating kinematically-consistent displacement corrections produces a scheme that is demonstrably better at estimating partially observed state vectors in a setting where feature information is important. While the displacement transformation is generic, here we implement it within an ensemble Kalman Filter framework and demonstrate its effectiveness in tracking stochastically perturbed vortices.},
  urldate  = {2023-12-24},
  journal  = {Journal of Computational Physics},
  author   = {Rosenthal, W. Steven and Venkataramani, Shankar and Mariano, Arthur J. and Restrepo, Juan M.},
  month    = feb,
  year     = {2017},
  keywords = {Uncertainty quantification, Data assimilation, Ensemble Kalman Filter, Displacement assimilation, Vortex dynamics},
  pages    = {594--614},
  file     = {ScienceDirect Snapshot:C\:\\Users\\md266594\\Zotero\\storage\\L6ZSVYH7\\S002199911630523X.html:text/html;Version soumise:C\:\\Users\\md266594\\Zotero\\storage\\DHP5HUMT\\Rosenthal et al. - 2017 - Displacement data assimilation.pdf:application/pdf}
}


@book{book_vortex,
  author = {Cottet, G.-H and Koumoutsakos, Petros},
  year   = {2000},
  month  = {03},
  pages  = {},
  title  = {Vortex methods - theory and practice.},
  isbn   = {978-0-521-62186-1},
  doi    = {10.1017/CBO9780511526442}
}

@phdthesis{feyeu2016,
  url    = {http://www.theses.fr/2016GREAM076},
  title  = {Transport optimal pour l'assimilation de données images},
  author = {Feyeux, Nelson},
  year   = {2016},
  note   = {Thèse de doctorat dirigée par Vidard, Arthur et Nodet, Maëlle Mathématiques appliquées Université Grenoble Alpes (ComUE) 2016},
  note   = {2016GREAM076},
  url    = {http://www.theses.fr/2016GREAM076/document}
}


